# ğŸ“ AlSign ì´ìŠˆ ìƒì„¸ë„

> ì´ ë¬¸ì„œëŠ” ê° ì´ìŠˆì˜ ë¬¸ì œê°€ ëœ ì½”ë“œì™€ ì ìš©í•  ì½”ë“œë¥¼ ìƒì„¸íˆ ê¸°ë¡í•©ë‹ˆë‹¤.
> ê° í•­ëª©ì€ `1_CHECKLIST.md` ë° `2_FLOW.md`ì™€ ë™ì¼í•œ `I-##` IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
>
> **ID ì²´ê³„**: ëª¨ë“  ë¬¸ì„œì—ì„œ ë™ì¼í•œ `I-##` IDë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

---

## I-01: consensusSignal ì„¤ì • ë¶ˆì¼ì¹˜

### I-01-A: SQL ë³€ê²½ (ë°˜ì˜ì™„ë£Œ - ì‹¤í–‰ëŒ€ê¸°)

	**íŒŒì¼**: `backend/scripts/apply_issue_docs_changes.sql`
	
	**ë¬¸ì œê°€ ëœ ì„¤ì •**:
	```sql
	-- ê¸°ì¡´ config_lv2_metric í…Œì´ë¸”ì˜ consensusSignal
	id: consensusSignal
	source: expression
	expression: buildConsensusSignal(consensusWithPrev)  -- âŒ consensusWithPrev ë¯¸ì¡´ì¬
	domain: qualatative-consensusSignal
	```
	
	**ì ìš©í•  ë³€ê²½**:
	```sql
	-- consensusSignalì„ aggregation íƒ€ì…ìœ¼ë¡œ ë³€ê²½
	UPDATE config_lv2_metric
	SET
	  source = 'aggregation',
	  expression = NULL,  -- ì˜ì¡´ì„± ì œê±°
	  base_metric_id = NULL,  -- consensusRaw êµ¬í˜„ í›„ ì¶”ê°€ í•„ìš”
	  aggregation_kind = 'leadPairFromList',
	  aggregation_params = '{
	    "partitionBy": ["ticker", "analyst_name", "analyst_company"],
	    "orderBy": [{"event_date": "desc"}],
	    "leadFields": [
	      {"field": "price_target", "as": "price_target_prev"},
	      {"field": "price_when_posted", "as": "price_when_posted_prev"}
	    ],
	    "emitPrevRow": true
	  }'::jsonb,
	  description = 'Consensus signal built from evt_consensus using aggregation...'
	WHERE id = 'consensusSignal';
	```

### I-01-B: leadPairFromList aggregation êµ¬í˜„ (ë¯¸ë°˜ì˜)

	**í•„ìš” íŒŒì¼**: `backend/src/services/metric_engine.py`
	
	**í˜„ì¬ ìƒíƒœ**: aggregation ë¼ìš°íŒ…ì— leadPairFromList ì—†ìŒ
	
	```python
	# í˜„ì¬ ì½”ë“œ (metric_engine.py ~438ì¤„)
	if aggregation_kind == 'ttmFromQuarterSumOrScaled':
	    return self._ttm_sum_or_scaled(base_values, aggregation_params)
	elif aggregation_kind == 'lastFromQuarter':
	    return self._last_from_quarter(base_values, aggregation_params)
	# ... leadPairFromList ì—†ìŒ!
	```
	
	**ì¶”ê°€í•´ì•¼ í•  ì½”ë“œ**:
	```python
	elif aggregation_kind == 'leadPairFromList':
	    return self._lead_pair_from_list(base_values, aggregation_params)
	
	def _lead_pair_from_list(
	    self,
	    base_values: List[Dict[str, Any]],
	    params: Dict[str, Any]
	) -> Optional[Dict[str, Any]]:
	    """
	    Find previous record for same partition and attach lead values.
	    
	    Args:
	        base_values: List of records from base_metric
	        params: {
	            "partitionBy": ["ticker", "analyst_name", "analyst_company"],
	            "orderBy": [{"event_date": "desc"}],
	            "leadFields": [{"field": "price_target", "as": "price_target_prev"}],
	            "emitPrevRow": true
	        }
	    
	    Returns:
	        Dict with current record + prev values
	    """
	    partition_by = params.get('partitionBy', [])
	    order_by = params.get('orderBy', [])
	    lead_fields = params.get('leadFields', [])
	    
	    # Implementation: partition, sort, find prev, attach lead fields
	    # ...
	```

---

## I-02: priceEodOHLC dict response_key

### ê²€ì¦ ê²°ê³¼ (ì¡°ì¹˜ ë¶ˆí•„ìš”)

	**íŒŒì¼**: `backend/src/services/metric_engine.py`
	
	**í™•ì¸ëœ ì½”ë“œ** (ë¼ì¸ 385-422):
	```python
	def _calculate_api_field(self, metric, api_data):
	    # ...
	    
	    # Handle dict response_key (complex schema mapping)
	    if isinstance(field_key, dict):
	        # âœ… dict í˜•íƒœ ì§€ì› í™•ì¸ë¨!
	        if isinstance(api_response, list):
	            result_list = []
	            for record in api_response:
	                record_dict = {}
	                for output_key, api_key in field_key.items():
	                    value = record.get(api_key)
	                    if value is not None:
	                        record_dict[output_key] = self._convert_value(value)
	                if record_dict:
	                    result_list.append(record_dict)
	            
	            if len(result_list) == 1:
	                return result_list[0]
	            elif len(result_list) > 1:
	                return result_list
	            else:
	                return None
	```
	
	**ê²°ë¡ **: dict response_key `{"low": "low", "high": "high", "open": "open", "close": "close"}`ê°€ ì •ìƒ ì§€ì›ë¨.

---

## I-03: targetMedian & consensusSummary êµ¬í˜„

### Python ì½”ë“œ ë³€ê²½ (ë°˜ì˜ì™„ë£Œ)

	**íŒŒì¼**: `backend/src/services/valuation_service.py`
	
	**ë³€ê²½ ì „** (ë¼ì¸ ~723):
	```python
	value_qualitative = {
	    'consensusSignal': consensus_signal  # âŒ targetMedian, consensusSummary ì—†ìŒ
	}
	```
	
	**ë³€ê²½ í›„** (ë¼ì¸ 678-728):
	```python
	# I-03 ì ìš©: targetMedian & consensusSummary ê³„ì‚°
	target_median = 0
	consensus_summary = None
	
	try:
	    # 1. qualatative-consensusSummary ë„ë©”ì¸ ë©”íŠ¸ë¦­ ë¡œë“œ
	    consensus_summary_metrics = await metrics.select_metrics_by_domain_prefix(
	        pool, 'qualatative-consensusSummary'
	    )
	    
	    if consensus_summary_metrics:
	        # 2. FMP API í˜¸ì¶œí•˜ì—¬ consensus summary ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
	        async with FMPAPIClient() as fmp_client:
	            api_data = {}
	            consensus_target_data = await fmp_client.call_api(
	                'fmp-price-target-consensus',
	                {'ticker': ticker}
	            )
	            if consensus_target_data:
	                api_data['fmp-price-target-consensus'] = (
	                    consensus_target_data if isinstance(consensus_target_data, list) 
	                    else [consensus_target_data]
	                )
	            
	            # 3. MetricCalculationEngineìœ¼ë¡œ ê³„ì‚°
	            engine = MetricCalculationEngine(
	                metrics_by_domain={'consensusSummary': consensus_summary_metrics}
	            )
	            engine.build_dependency_graph()
	            engine.topological_sort()
	            
	            calculated = engine.calculate_all(
	                api_data=api_data,
	                target_domains=['consensusSummary']
	            )
	            
	            # 4. consensusSummary ì¶”ì¶œ
	            if 'consensusSummary' in calculated:
	                consensus_summary = calculated['consensusSummary'].get('consensusSummary')
	                
	                # 5. targetMedian ì¶”ì¶œ
	                if isinstance(consensus_summary, dict):
	                    target_median = consensus_summary.get('targetMedian', 0)
	                    
	except Exception as e:
	    logger.warning(f"Failed to calculate consensusSummary/targetMedian: {e}")
	
	# value_qualitative êµ¬ì„± (ì„¸ í•­ëª© ëª¨ë‘ í¬í•¨)
	value_qualitative = {
	    'targetMedian': target_median,           # âœ… ì¶”ê°€ë¨
	    'consensusSummary': consensus_summary,   # âœ… ì¶”ê°€ë¨
	    'consensusSignal': consensus_signal      # ê¸°ì¡´ ìœ ì§€
	}
	```

---

## I-05: consensus ë©”íŠ¸ë¦­ ì¶”ê°€

### SQL ë³€ê²½ (ë°˜ì˜ì™„ë£Œ - ì‹¤í–‰ëŒ€ê¸°)

	**íŒŒì¼**: `backend/scripts/apply_issue_docs_changes.sql`
	
	**ì¶”ê°€í•  ë©”íŠ¸ë¦­**:
	```sql
	INSERT INTO config_lv2_metric (id, source, api_list_id, response_key, domain, description)
	VALUES (
	  'consensus',
	  'api_field',
	  'fmp-price-target',
	  '{
	    "ticker": "symbol",
	    "newsURL": "newsURL",
	    "newsTitle": "newsTitle",
	    "event_date": "publishedDate",
	    "analystName": "analystName",
	    "newsBaseURL": "newsBaseURL",
	    "priceTarget": "priceTarget",
	    "newsPublisher": "newsPublisher",
	    "publishedDate": "publishedDate",
	    "adjPriceTarget": "adjPriceTarget",
	    "analystCompany": "analystCompany",
	    "priceWhenPosted": "priceWhenPosted"
	  }'::jsonb,
	  'qualatative-consensus',
	  'Consensus data from fmp-price-target API. Includes analyst info, news details, and price targets.'
	)
	ON CONFLICT (id) DO UPDATE SET
	  source = EXCLUDED.source,
	  api_list_id = EXCLUDED.api_list_id,
	  response_key = EXCLUDED.response_key,
	  domain = EXCLUDED.domain,
	  description = EXCLUDED.description;
	```

---

## I-07: source_id íŒŒë¼ë¯¸í„° ì¶”ê°€

### Python ì½”ë“œ ë³€ê²½ (ë°˜ì˜ì™„ë£Œ)

	**íŒŒì¼**: `backend/src/services/valuation_service.py`
	
	**ë³€ê²½ ì „**:
	```python
	async def calculate_qualitative_metrics(
	    pool,
	    ticker: str,
	    event_date,
	    source: str  # âŒ source_id ì—†ìŒ!
	) -> Dict[str, Any]:
	    # ...
	    consensus_data = await metrics.select_consensus_data(
	        pool, ticker, event_date  # âŒ source_id ì—†ìŒ!
	    )
	```
	
	**ë³€ê²½ í›„** (ë¼ì¸ 578-621):
	```python
	async def calculate_qualitative_metrics(
	    pool,
	    ticker: str,
	    event_date,
	    source: str,
	    source_id: str  # âœ… ì¶”ê°€ë¨
	) -> Dict[str, Any]:
	    """
	    Calculate qualitative metrics.
	    
	    Uses source_id to find the exact evt_consensus row,
	    ensuring we compare the same analyst's previous values.
	    """
	    # ...
	    consensus_data = await metrics.select_consensus_data(
	        pool, ticker, event_date, source_id  # âœ… source_id ì „ë‹¬
	    )
	```
	
	**íŒŒì¼**: `backend/src/database/queries/metrics.py`
	
	**ë³€ê²½ í›„** (select_consensus_data í•¨ìˆ˜):
	```python
	async def select_consensus_data(
	    pool: asyncpg.Pool,
	    ticker: str,
	    event_date,
	    source_id: str  # âœ… ì¶”ê°€ë¨
	) -> Dict[str, Any]:
	    async with pool.acquire() as conn:
	        row = await conn.fetchrow(
	            """
	            SELECT id, ticker, event_date, analyst_name, analyst_company,
	                   price_target, price_when_posted,
	                   price_target_prev, price_when_posted_prev,
	                   direction, response_key
	            FROM evt_consensus
	            WHERE id = $1        -- âœ… source_idë¡œ ì •í™•í•œ í–‰ ì¡°íšŒ
	              AND ticker = $2
	              AND event_date = $3
	            """,
	            source_id,  # âœ… ì •í™•í•œ í–‰ ì°¾ê¸°
	            ticker,
	            event_date
	        )
	        return dict(row) if row else None
	```

---

## I-08: ì‹œê°„ì  ìœ íš¨ì„± (Temporal Validity)

### Python ì½”ë“œ ë³€ê²½ (ë°˜ì˜ì™„ë£Œ)

	**íŒŒì¼**: `backend/src/services/valuation_service.py`
	
	**ë³€ê²½ ì „**:
	```python
	# FMP API í˜¸ì¶œ
	income_stmt = await fmp_client.get_income_statement(ticker, period='quarter', limit=4)  # âŒ limit=4 ê³ ì •
	balance_sheet = await fmp_client.get_balance_sheet(ticker, period='quarter', limit=4)
	```
	
	**ë³€ê²½ í›„** (ë¼ì¸ 425-504):
	```python
	# 1. limit=100ìœ¼ë¡œ ë³€ê²½
	income_stmt_all = await fmp_client.get_income_statement(ticker, period='quarter', limit=100)
	balance_sheet_all = await fmp_client.get_balance_sheet(ticker, period='quarter', limit=100)
	
	# 2. event_date ë³€í™˜
	if isinstance(event_date, str):
	    event_date_obj = datetime.fromisoformat(event_date.replace('Z', '+00:00')).date()
	elif hasattr(event_date, 'date'):
	    event_date_obj = event_date.date()
	else:
	    event_date_obj = event_date
	
	# 3. event_date ê¸°ì¤€ í•„í„°ë§
	for api_id, data in api_data_raw.items():
	    if isinstance(data, list):
	        filtered_data = []
	        for record in data:
	            record_date_str = record.get('date')
	            if record_date_str:
	                try:
	                    record_date = datetime.fromisoformat(
	                        record_date_str.replace('Z', '+00:00')
	                    ).date()
	                    if record_date <= event_date_obj:  # âœ… ì´ì „ ë¶„ê¸°ë§Œ ì‚¬ìš©
	                        filtered_data.append(record)
	                except:
	                    pass
	        api_data[api_id] = filtered_data
	        logger.info(f"Filtered {api_id}: {len(data)} -> {len(filtered_data)} records")
	
	# 4. ë°ì´í„° ì—†ì„ ì‹œ ì—ëŸ¬
	if not has_data:
	    return {
	        'status': 'failed',
	        'value': None,
	        'message': f'no_valid_data: No data available before event_date {event_date_obj}'
	    }
	
	# 5. _meta ì •ë³´ ê¸°ë¡
	value_quantitative[domain_key]['_meta'] = {
	    'date_range': {
	        'start': quarterly_data[3].get('date'),
	        'end': quarterly_data[0].get('date')
	    },
	    'calcType': 'TTM_fullQuarter' if quarters_used >= 4 else 'TTM_partialQuarter',
	    'count': quarters_used,
	    'event_date': str(event_date_obj),
	    'sector': company_info.get('sector'),
	    'industry': company_info.get('industry')
	}
	```

---

## I-09: Topological Sort ìˆœì„œ ìˆ˜ì •

### Python ì½”ë“œ ë³€ê²½ (ë°˜ì˜ì™„ë£Œ)

	**íŒŒì¼**: `backend/src/services/metric_engine.py`
	
	**ë³€ê²½ ì „** (ë¼ì¸ 121-163):
	```python
	# âŒ ì˜ëª»ëœ ë¡œì§: ì˜ì¡´ì„±ì— ëŒ€í•´ in-degree ì¦ê°€
	for dependency in dependencies:
	    in_degree[dependency] += 1  # âŒ ë°˜ëŒ€ë¡œ ë¨
	```
	
	**ë³€ê²½ í›„**:
	```python
	def topological_sort(self):
	    """
	    Topological sort using Kahn's algorithm.
	    Ensures api_field metrics (no dependencies) are calculated first.
	    """
	    # in-degree: ì´ ë©”íŠ¸ë¦­ì´ ì˜ì¡´í•˜ëŠ” ë©”íŠ¸ë¦­ ê°œìˆ˜
	    in_degree = {m: 0 for m in self.metrics_by_name.keys()}
	    
	    # ì—­ë°©í–¥ ê·¸ë˜í”„: ê° ë©”íŠ¸ë¦­ì— ì˜ì¡´í•˜ëŠ” ë©”íŠ¸ë¦­ë“¤
	    reverse_graph = defaultdict(list)
	    
	    # ì˜ì¡´ì„± ë¶„ì„
	    for metric_name, metric in self.metrics_by_name.items():
	        dependencies = self._get_dependencies(metric)
	        
	        # âœ… ì˜¬ë°”ë¥¸ ë¡œì§: ë©”íŠ¸ë¦­ ìì²´ì˜ in-degreeë¥¼ ì˜ì¡´ì„± ê°œìˆ˜ë¡œ ì„¤ì •
	        in_degree[metric_name] = len(dependencies)
	        
	        # ì—­ë°©í–¥ ê·¸ë˜í”„ êµ¬ì¶•
	        for dep in dependencies:
	            reverse_graph[dep].append(metric_name)
	    
	    # âœ… ì˜ì¡´ì„±ì´ ì—†ëŠ” ë©”íŠ¸ë¦­(api_field)ë¶€í„° ì‹œì‘
	    queue = deque([m for m, degree in in_degree.items() if degree == 0])
	    
	    sorted_order = []
	    while queue:
	        metric = queue.popleft()
	        sorted_order.append(metric)
	        
	        # ì´ ë©”íŠ¸ë¦­ì— ì˜ì¡´í•˜ëŠ” ë©”íŠ¸ë¦­ë“¤ì˜ in-degree ê°ì†Œ
	        for dependent in reverse_graph[metric]:
	            in_degree[dependent] -= 1
	            if in_degree[dependent] == 0:
	                queue.append(dependent)
	    
	    self.sorted_metrics = sorted_order
	```

---

## I-10: priceEodOHLC_dateRange ì •ì±… ë¶„ë¦¬ (ë¯¸ë°˜ì˜)

### í•„ìš”í•œ ë³€ê²½

	**íŒŒì¼**: `backend/src/database/queries/policies.py`
	
	**ì¶”ê°€í•´ì•¼ í•  í•¨ìˆ˜**:
	```python
	async def get_ohlc_date_range_policy(pool: asyncpg.Pool) -> Dict[str, int]:
	    """
	    Get OHLC API fetch date range policy.
	    Uses priceEodOHLC_dateRange policy, separate from fillPriceTrend_dateRange.
	    
	    Returns:
	        Dict with countStart, countEnd (calendar days)
	    """
	    policy = await select_policy(pool, 'priceEodOHLC_dateRange')
	    if not policy:
	        raise ValueError("Policy 'priceEodOHLC_dateRange' not found")
	    
	    policy_config = policy['policy']
	    return {
	        'countStart': int(policy_config['countStart']),
	        'countEnd': int(policy_config['countEnd'])
	    }
	```
	
	**íŒŒì¼**: `backend/src/services/valuation_service.py`
	
	**ë³€ê²½í•´ì•¼ í•  ì½”ë“œ**:
	```python
	# í˜„ì¬ (ì˜ëª»ë¨)
	fetch_start = min_date + timedelta(days=count_start * 2)  # âŒ fillPriceTrend_dateRange ì¬ì‚¬ìš©
	
	# ìˆ˜ì • í›„ (ì§€ì¹¨ ì¤€ìˆ˜)
	ohlc_policy = await policies.get_ohlc_date_range_policy(pool)
	fetch_start = min_date + timedelta(days=ohlc_policy['countStart'])  # âœ… ë³„ë„ ì •ì±… ì‚¬ìš©
	fetch_end = max_date + timedelta(days=ohlc_policy['countEnd'])
	```

---

## I-11: internal(qual) ë©”íŠ¸ë¦­ ë™ì  ì‚¬ìš© (ë¯¸ë°˜ì˜)

### í•„ìš”í•œ ë³€ê²½

	**íŒŒì¼**: `backend/src/database/queries/metrics.py`
	
	**ì¶”ê°€í•´ì•¼ í•  í•¨ìˆ˜**:
	```python
	async def select_internal_qual_metrics(pool: asyncpg.Pool) -> List[Dict[str, Any]]:
	    """
	    Select internal(qual) metrics for analyst performance calculation.
	    
	    Filters by:
	        - domain = 'internal(qual)'
	        - base_metric_id = 'priceTrendReturnSeries'
	    """
	    async with pool.acquire() as conn:
	        rows = await conn.fetch("""
	            SELECT id, domain, expression, description,
	                   source, base_metric_id, aggregation_kind, 
	                   aggregation_params, response_key
	            FROM config_lv2_metric
	            WHERE domain = 'internal(qual)'
	              AND base_metric_id = 'priceTrendReturnSeries'
	            ORDER BY id
	        """)
	        return [dict(row) for row in rows]
	```
	
	**íŒŒì¼**: `backend/src/services/analyst_service.py`
	
	**ë³€ê²½í•´ì•¼ í•  ì½”ë“œ**:
	```python
	# í˜„ì¬ (í•˜ë“œì½”ë”©)
	stats = analyst.calculate_statistics(returns)  # âŒ í•˜ë“œì½”ë”©ëœ í†µê³„ ê³„ì‚°
	
	# ìˆ˜ì • í›„ (DB ì •ì˜ ê¸°ë°˜)
	internal_metrics = await metrics.select_internal_qual_metrics(pool)
	if not internal_metrics:
	    return {'error': 'METRIC_NOT_FOUND', ...}
	
	# DB ë©”íŠ¸ë¦­ ì •ì˜ì—ì„œ í†µê³„ í•¨ìˆ˜ ë§¤í•‘
	# Mean â† returnMeanByDayOffset
	# Median â† returnMedianByDayOffset
	# 1stQuartile â† returnFirstQuartileByDayOffset
	# 3rdQuartile â† returnThirdQuartileByDayOffset
	# InterquartileRange â† returnIQRByDayOffset
	# standardDeviation â† returnStdDevByDayOffset
	# count â† returnCountByDayOffset
	```

---

## SQL ì‹¤í–‰ ìˆœì„œ

### 1ë‹¨ê³„: ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ì„¤ì • (ì•„ì§ ë¯¸ì‹¤í–‰ ì‹œ)
	```bash
	# Supabase SQL Editorì—ì„œ ì‹¤í–‰
	backend/scripts/setup_supabase.sql
	```

### 2ë‹¨ê³„: ì´ìŠˆ ë°˜ì˜ SQL
	```bash
	# Supabase SQL Editorì—ì„œ ì‹¤í–‰
	backend/scripts/apply_issue_docs_changes.sql
	```

### ê²€ì¦ ì¿¼ë¦¬
	```sql
	-- I-01: consensusSignal ì„¤ì • í™•ì¸
	SELECT id, source, expression, aggregation_kind, domain
	FROM config_lv2_metric
	WHERE id = 'consensusSignal';
	
	-- I-05: consensus ë©”íŠ¸ë¦­ ì¶”ê°€ í™•ì¸
	SELECT id, source, api_list_id, domain
	FROM config_lv2_metric
	WHERE id = 'consensus';
	
	-- ì „ì²´ qualatative ë©”íŠ¸ë¦­ í™•ì¸
	SELECT id, source, domain
	FROM config_lv2_metric
	WHERE domain LIKE 'qualatative-%'
	ORDER BY id;
	```

---

## I-12: ë™ì  ê³„ì‚° ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨

### I-12-A: ë¬¸ì œ ë¡œê·¸ ë¶„ì„

**ë¡œê·¸ ì¶œë ¥**:
```
[MetricEngine] Dynamic calculation execution failed: invalid syntax (<string>, line 2)
[MetricEngine] Dynamic calculation failed for yoyFromQuarter, falling back to hardcoded: invalid syntax (<string>, line 2)
```

**ì˜í–¥ë°›ëŠ” í•¨ìˆ˜ë“¤**:
- `yoyFromQuarter`: ì „ë…„ë™ê¸° ëŒ€ë¹„ ì¦ê°ë¥ 
- `qoqFromQuarter`: ì „ë¶„ê¸° ëŒ€ë¹„ ì¦ê°ë¥   
- `lastFromQuarter`: ìµœì‹  1ê°œ ê°’ ë°˜í™˜
- `avgFromQuarter`: ë¶„ê¸° í‰ê· 
- `ttmFromQuarterSumOrScaled`: TTM í•©ì‚°

**í˜„ì¬ ë™ì‘**:
```python
# backend/src/services/metric_engine.py:494-508
transform_def = self.transforms.get(aggregation_kind)
if transform_def and transform_def.get('calculation'):
    try:
        return self._execute_dynamic_calculation(
            transform_def['calculation'],
            base_values,
            aggregation_params
        )
    except Exception as e:
        logger.warning(
            f"[MetricEngine] Dynamic calculation failed for {aggregation_kind}, "
            f"falling back to hardcoded: {e}"
        )
        # Fall through to hardcoded functions âœ… í´ë°± ì‘ë™
```

### I-12-B: ì›ì¸ ë¶„ì„

**calculation ì»¬ëŸ¼ ì½”ë“œ ì˜ˆì‹œ** (seed_calculation_codes.sql):
```sql
UPDATE config_lv2_metric_transform
SET calculation = $$
if not quarterly_values:
    return None

current = quarterly_values[0]
previous = quarterly_values[1]

if previous == 0:
    return None

return (current - previous) / previous
$$
WHERE id = 'qoqFromQuarter';
```

**ë¬¸ì œì **:
1. `$$` êµ¬ë¶„ìë¡œ ê°ì‹¼ ì½”ë“œê°€ DBì— ì €ì¥ë  ë•Œ ê³µë°±ì´ë‚˜ ê°œí–‰ ë¬¸ì í¬í•¨
2. `eval()` ì‹¤í–‰ ì‹œ ì²« ì¤„ íŒŒì‹± ì—ëŸ¬ ë°œìƒ
3. Pythonì˜ `eval()`ì€ single expressionë§Œ ì§€ì›í•˜ë‚˜, ì½”ë“œëŠ” multiple statements

### I-12-C: í•´ê²° ë°©ì•ˆ

**ì˜µì…˜ A: exec() ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½** (ê¶Œì¥)
```python
# backend/src/services/metric_engine.py:526-608
def _execute_dynamic_calculation(
    self,
    calculation_code: str,
    quarterly_values: List[float],
    params: Dict[str, Any]
) -> Any:
    # ... namespace ì„¤ì • ...
    
    try:
        # eval() â†’ exec() + return value ì¶”ì¶œ
        local_vars = {}
        exec(calculation_code, safe_namespace, local_vars)
        return local_vars.get('result')  # ì½”ë“œê°€ result ë³€ìˆ˜ ì„¤ì • í•„ìš”
    except Exception as e:
        logger.error(f"[MetricEngine] Dynamic calculation execution failed: {e}")
        logger.debug(f"[MetricEngine] Calculation code: {calculation_code[:200]}...")
        raise
```

**ì˜µì…˜ B: calculation ì½”ë“œ ì¬ì‘ì„±**
```sql
-- qoqFromQuarterë¥¼ single expressionìœ¼ë¡œ ë³€ê²½
UPDATE config_lv2_metric_transform
SET calculation = 'None if len(quarterly_values) < 2 or quarterly_values[1] == 0 else (quarterly_values[0] - quarterly_values[1]) / quarterly_values[1]'
WHERE id = 'qoqFromQuarter';
```

**ì˜µì…˜ C: í•˜ë“œì½”ë”© ìœ ì§€** (í˜„ì¬ ìƒíƒœ)
- ì¥ì : ì´ë¯¸ í…ŒìŠ¤íŠ¸ë˜ê³  ì•ˆì •ì 
- ë‹¨ì : DB ì„¤ì •ê³¼ ë¶ˆì¼ì¹˜

### I-12-D: ê²€ì¦ SQL

```sql
-- calculation ì»¬ëŸ¼ ë‚´ìš© í™•ì¸
SELECT 
    id, 
    calculation,
    LENGTH(calculation) as code_length,
    LEFT(calculation, 50) as first_50_chars
FROM config_lv2_metric_transform
WHERE calculation IS NOT NULL
ORDER BY id;

-- ë¬¸ì œê°€ ìˆëŠ” ì½”ë“œ í™•ì¸
SELECT id, calculation
FROM config_lv2_metric_transform  
WHERE calculation LIKE E'%\n%'  -- ê°œí–‰ ë¬¸ì í¬í•¨
   OR calculation LIKE '  %';    -- ì‹œì‘ ê³µë°± í¬í•¨
```

### I-12-E: ì ìš©ëœ í•´ê²° ë°©ì•ˆ (ë°˜ì˜ì™„ë£Œ)

**íŒŒì¼**: `backend/scripts/fix_calculation_single_expression.sql`

**ìˆ˜ì • ë‚´ìš©**:
```sql
-- avgFromQuarter: ë¶„ê¸° ì‹œê³„ì—´ í‰ê· 
UPDATE config_lv2_metric_transform
SET calculation = 'None if not quarterly_values else sum(quarterly_values[:params.get("window", 4)]) / len(quarterly_values[:params.get("window", 4)])'
WHERE id = 'avgFromQuarter';

-- ttmFromQuarterSumOrScaled: TTM í•©ì‚°
UPDATE config_lv2_metric_transform
SET calculation = 'None if not quarterly_values or len(quarterly_values[:params.get("window", 4)]) < params.get("min_points", 1) else (lambda recent: sum(recent) if len(recent) >= params.get("scale_to", 4) else (sum(recent) / len(recent)) * params.get("scale_to", 4))(quarterly_values[:params.get("window", 4)])'
WHERE id = 'ttmFromQuarterSumOrScaled';

-- lastFromQuarter: ìµœì‹  ê°’ ë°˜í™˜
UPDATE config_lv2_metric_transform
SET calculation = 'None if not quarterly_values else quarterly_values[0]'
WHERE id = 'lastFromQuarter';

-- qoqFromQuarter: ì „ë¶„ê¸° ëŒ€ë¹„ ì¦ê°ë¥ 
UPDATE config_lv2_metric_transform
SET calculation = 'None if len(quarterly_values) < 2 or quarterly_values[1] == 0 else (quarterly_values[0] - quarterly_values[1]) / quarterly_values[1]'
WHERE id = 'qoqFromQuarter';

-- yoyFromQuarter: ì „ë…„ë™ê¸° ëŒ€ë¹„ ì¦ê°ë¥ 
UPDATE config_lv2_metric_transform
SET calculation = 'None if len(quarterly_values) < 5 or quarterly_values[4] == 0 else (quarterly_values[0] - quarterly_values[4]) / quarterly_values[4]'
WHERE id = 'yoyFromQuarter';
```

**í•µì‹¬ ë³€ê²½**:
- multiple statements â†’ single expression
- lambda í•¨ìˆ˜ í™œìš©ìœ¼ë¡œ ë³µì¡í•œ ë¡œì§ í‘œí˜„
- conditional expression (ternary operator) ì‚¬ìš©

---

## I-13: priceEodOHLC ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨

### I-13-A: ë¬¸ì œ ë¡œê·¸ ë¶„ì„

**ë¡œê·¸ ì¶œë ¥**:
```
[calculate_quantitative_metrics] Fetched fmp-historical-price-eod-full: 1176 records
[calculate_quantitative_metrics] Filtered fmp-historical-price-eod-full: 1176 -> 0 records for event_date 2021-01-31

# ë‘ ë²ˆì§¸ ì´ë²¤íŠ¸
[calculate_quantitative_metrics] Filtered fmp-historical-price-eod-full: 1176 -> 39 records for event_date 2021-06-16
[priceEodOHLC] Dict response_key processing: field_key={'low': 'low', 'high': 'high', 'open': 'open', 'close': 'close'}, api_response type=<class 'list'>, len=39
[priceEodOHLC] Extracted 0 dicts from 39 records
[priceEodOHLC] Returning None: result_list is empty
```

**ë¬¸ì œ**:
- APIì—ì„œ 1176ê°œ ë ˆì½”ë“œ ë°›ìŒ
- ë‚ ì§œ í•„í„°ë§ìœ¼ë¡œ 39ê°œë¡œ ì¶•ì†Œë¨
- **í•„ë“œ ë§¤í•‘ì—ì„œ 0ê°œ ì¶”ì¶œ** â† í•µì‹¬ ë¬¸ì œ

### I-13-B: ì›ì¸ ë¶„ì„

**í˜„ì¬ ì„¤ì •** (config_lv2_metric):
```json
{
  "id": "priceEodOHLC",
  "api_list_id": "fmp-historical-price-eod-full",
  "response_key": {
    "low": "low",
    "high": "high", 
    "open": "open",
    "close": "close"
  }
}
```

**í•„ë“œ ì¶”ì¶œ ë¡œì§** (metric_engine.py:389-414):
```python
for record in api_response:
    record_dict = {}
    for output_key, api_key in field_key.items():
        value = record.get(api_key)  # â† ì—¬ê¸°ì„œ None ë°˜í™˜ë¨
        if value is not None:
            record_dict[output_key] = self._convert_value(value)
    if record_dict:  # â† record_dictê°€ ë¹„ì–´ìˆì–´ì„œ ì¶”ê°€ ì•ˆë¨
        result_list.append(record_dict)
```

**ì˜ˆìƒ ì›ì¸**:
1. FMP APIê°€ `low`, `high`, `open`, `close` í•„ë“œëª… ëŒ€ì‹  ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©
2. ê°€ëŠ¥í•œ ì‹¤ì œ í•„ë“œëª…: `adjClose`, `adjHigh`, `adjLow`, `adjOpen` (adjusted ê°’)
3. ë˜ëŠ”: `unadjustedClose`, `unadjustedHigh` ë“±

### I-13-C: ê²€ì¦ SQL

```sql
-- 1. priceEodOHLC ë©”íŠ¸ë¦­ ì„¤ì • í™•ì¸
SELECT 
    id,
    api_list_id,
    response_key::text,
    domain,
    source
FROM config_lv2_metric 
WHERE id = 'priceEodOHLC';

-- 2. fmp-historical-price-eod-full API ìŠ¤í‚¤ë§ˆ í™•ì¸
SELECT 
    api,
    endpoint,
    schema::text as response_schema
FROM config_lv1_api_list 
WHERE api = 'fmp-historical-price-eod-full';

-- 3. API ìŠ¤í‚¤ë§ˆì—ì„œ ì‹¤ì œ í•„ë“œëª… í™•ì¸
SELECT 
    api,
    jsonb_object_keys(schema) as field_name
FROM config_lv1_api_list 
WHERE api = 'fmp-historical-price-eod-full';
```

### I-13-D: í•´ê²° ë°©ì•ˆ

**ì˜µì…˜ A: response_key ìˆ˜ì •** (ê¶Œì¥ - ê°„ë‹¨)
```sql
-- adjusted í•„ë“œ ì‚¬ìš©
UPDATE config_lv2_metric
SET response_key = '{
    "low": "adjLow",
    "high": "adjHigh",
    "open": "adjOpen",
    "close": "adjClose"
}'::jsonb
WHERE id = 'priceEodOHLC';
```

**ì˜µì…˜ B: ë‘ ê°€ì§€ í•„ë“œ ëª¨ë‘ ì§€ì›** (ì•ˆì „)
```python
# metric_engine.py ìˆ˜ì •
for output_key, api_key in field_key.items():
    # Try adjusted field first, fallback to unadjusted
    value = record.get(f"adj{api_key.capitalize()}") or record.get(api_key)
    if value is not None:
        record_dict[output_key] = self._convert_value(value)
```

**ì˜µì…˜ C: API ì‘ë‹µ ë¡œê¹… ê°•í™”**
```python
# valuation_service.pyì— ì„ì‹œ ë¡œê¹… ì¶”ê°€
if api_id == 'fmp-historical-price-eod-full' and data:
    logger.info(f"[DEBUG] OHLC API sample record: {data[0]}")
    logger.info(f"[DEBUG] OHLC API keys: {list(data[0].keys())}")
```

### I-13-E: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```python
# backend/test_ohlc_fields.py
import asyncio
import asyncpg

async def test_ohlc_fields():
    conn = await asyncpg.connect(
        "postgresql://postgres:password@localhost:54322/postgres"
    )
    
    # 1. í˜„ì¬ response_key í™•ì¸
    row = await conn.fetchrow(
        "SELECT response_key FROM config_lv2_metric WHERE id = 'priceEodOHLC'"
    )
    print(f"Current response_key: {row['response_key']}")
    
    # 2. API ìŠ¤í‚¤ë§ˆ í™•ì¸
    row = await conn.fetchrow(
        "SELECT schema FROM config_lv1_api_list WHERE api = 'fmp-historical-price-eod-full'"
    )
    print(f"\nAPI schema fields:")
    for key in row['schema'].keys():
        print(f"  - {key}")
    
    await conn.close()

asyncio.run(test_ohlc_fields())
```

### I-13-F: ì‹¤ì œ ì›ì¸ ë° í•´ê²° (ë°˜ì˜ì™„ë£Œ)

**ì‹¤ì œ ì›ì¸ ë°œê²¬**:
- FMP API ì‹¤ì œ ì‘ë‹µ í™•ì¸ ê²°ê³¼: í•„ë“œëª…ì€ `low`, `high`, `open`, `close`ë¡œ ì •í™•í•¨
- ë¬¸ì œëŠ” `calculate_quantitative_metrics()`ì—ì„œ API í˜¸ì¶œ ì‹œ **í•„ìˆ˜ íŒŒë¼ë¯¸í„° ëˆ„ë½**
- `fmp-historical-price-eod-full` APIëŠ” `{fromDate}`, `{toDate}` íŒŒë¼ë¯¸í„° í•„ìš”
- íŒŒë¼ë¯¸í„° ì—†ì´ í˜¸ì¶œí•˜ë©´ URLì— `{fromDate}`, `{toDate}` placeholderê°€ ê·¸ëŒ€ë¡œ ë‚¨ìŒ

**ë¡œê·¸ ì¦ê±°**:
```
URL template variable 'fromDate' not provided, keeping placeholder
URL template variable 'toDate' not provided, keeping placeholder
[API Call] fmp-historical-price-eod-full -> https://...?symbol=RGTI&from={fromDate}&to={toDate}&apikey=...
```

**ì ìš©í•œ ìˆ˜ì •** (`backend/src/services/valuation_service.py:431-456`):
```python
# ìˆ˜ì • ì „
for api_id in required_apis:
    result = await fmp_client.call_api(api_id, {
        'ticker': ticker,
        'period': 'quarter',
        'limit': 100
    })

# ìˆ˜ì • í›„
for api_id in required_apis:
    # Prepare API-specific parameters
    params = {'ticker': ticker}
    
    # Add API-specific parameters
    if 'historical-price' in api_id or 'eod' in api_id:
        # Historical price APIs need date range
        params['fromDate'] = '2000-01-01'  # Far past for sufficient data
        params['toDate'] = event_date_obj.strftime('%Y-%m-%d')
    else:
        # Quarterly financial APIs
        params['period'] = 'quarter'
        params['limit'] = 100
    
    result = await fmp_client.call_api(api_id, params)
```

**ì „ì²´ ì„œë¹„ìŠ¤ ì ê²€ ê²°ê³¼**:
- ì´ 11ê°œ `call_api()` í˜¸ì¶œ ìœ„ì¹˜ ê²€ì¦
- ëª¨ë“  ìœ„ì¹˜ì—ì„œ config_lv1_api_list ì‚¬ìš© í™•ì¸
- `get_historical_price_eod()` ë©”ì„œë“œëŠ” ì˜¬ë°”ë¥´ê²Œ íŒŒë¼ë¯¸í„° ì „ë‹¬
- ë¬¸ì œëŠ” `calculate_quantitative_metrics()`ì˜ ë™ì  API í˜¸ì¶œ ë¶€ë¶„ë§Œ í•´ë‹¹

**ê²€ì¦ í•„ìš” ì‚¬í•­**:
- ë‹¤ë¥¸ APIë“¤ë„ í•„ìˆ˜ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
- `config_lv1_api_list.api` ì»¬ëŸ¼ì˜ URL í…œí”Œë¦¿ ê²€í† 

---

## I-14: fmp-aftermarket-trade API 401 ì˜¤ë¥˜

### I-14-A: ë¬¸ì œ ë¡œê·¸ ë¶„ì„

**ë¡œê·¸ ì¶œë ¥**:
```
[API Call] fmp-aftermarket-trade -> https://financialmodelingprep.com/stable/aftermarket-trade?symbol=RGTI?apikey=8AP6lUDNsrBwtx5IzVoDliKnG186rBSt
[API Error] fmp-aftermarket-trade -> HTTPStatusError: Client error '401 Unauthorized'
[calculate_quantitative_metrics] Failed to fetch fmp-aftermarket-trade: Client error '401 Unauthorized'
```

**ë¬¸ì œì **:
1. **ì´ì¤‘ `?` ë¬¸ì**: `...?symbol=RGTI?apikey=...` â† ì˜ëª»ëœ URL
2. **401 Unauthorized**: API í‚¤ê°€ ìˆì§€ë§Œ ê¶Œí•œ ê±°ë¶€

### I-14-B: ì›ì¸ ë¶„ì„

**URL êµ¬ì„± ë¡œì§** (external_api.py):
```python
async def call_api(self, api_id: str, params: Dict[str, str] = None):
    # DBì—ì„œ endpoint í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
    api_config = self.api_configs.get(api_id)
    url_template = api_config['endpoint']  # ì˜ˆ: "...?symbol={ticker}"
    
    # íŒŒë¼ë¯¸í„° ì¹˜í™˜
    url = url_template.format(**params)
    
    # API í‚¤ ì¶”ê°€
    if '?' in url:
        url = f"{url}&apikey={api_key}"  # âœ… ì˜¬ë°”ë¦„
    else:
        url = f"{url}?apikey={api_key}"  # âŒ ì´ë¯¸ ?ê°€ ìˆìœ¼ë©´ ë¬¸ì œ
```

**DB ì„¤ì • í™•ì¸ í•„ìš”**:
```sql
SELECT api, endpoint
FROM config_lv1_api_list
WHERE api = 'fmp-aftermarket-trade';
```

**ì˜ˆìƒ DB ê°’**:
```
endpoint: "/aftermarket-trade?symbol={ticker}?"
                                            ^ ë¶ˆí•„ìš”í•œ ?
```

### I-14-C: í•´ê²° ë°©ì•ˆ

**ì˜µì…˜ A: DB endpoint ìˆ˜ì •** (ê¶Œì¥)
```sql
UPDATE config_lv1_api_list
SET endpoint = '/aftermarket-trade?symbol={ticker}'
WHERE api = 'fmp-aftermarket-trade';
```

**ì˜µì…˜ B: Python ì½”ë“œì—ì„œ ì²˜ë¦¬**
```python
# external_api.py: call_api í•¨ìˆ˜ ìˆ˜ì •
url = url_template.format(**params)

# URL ì •ê·œí™”: ì¤‘ë³µ ? ì œê±°
url = url.replace('??', '?').rstrip('?')

# API í‚¤ ì¶”ê°€
if '?' in url:
    url = f"{url}&apikey={api_key}"
else:
    url = f"{url}?apikey={api_key}"
```

**ì˜µì…˜ C: ë©”íŠ¸ë¦­ì„ optionalë¡œ ì²˜ë¦¬**
```python
# metric_engine.pyì—ì„œ priceAfter ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
if metric.get('name') == 'priceAfter' and api_response is None:
    logger.debug("[MetricEngine] priceAfter API unavailable, skipping")
    return None
```

**ì˜µì…˜ D: API ë¹„í™œì„±í™”**
```sql
-- aftermarket API ë¹„í™œì„±í™”
UPDATE config_lv1_api_list
SET is_active = false
WHERE api = 'fmp-aftermarket-trade';

-- ë˜ëŠ” priceAfter ë©”íŠ¸ë¦­ ë¹„í™œì„±í™”
UPDATE config_lv2_metric
SET domain = 'disabled'  -- internalì—ì„œ ì œì™¸
WHERE id = 'priceAfter';
```

### I-14-D: ê²€ì¦ SQL

```sql
-- 1. aftermarket API ì„¤ì • í™•ì¸
SELECT 
    api,
    endpoint,
    api_service,
    is_active
FROM config_lv1_api_list
WHERE api LIKE '%aftermarket%';

-- 2. priceAfter ë©”íŠ¸ë¦­ í™•ì¸  
SELECT 
    id,
    api_list_id,
    domain,
    response_key
FROM config_lv2_metric
WHERE id = 'priceAfter';

-- 3. endpointì— ? ë¬¸ì ê°œìˆ˜ í™•ì¸
SELECT 
    api,
    endpoint,
    LENGTH(endpoint) - LENGTH(REPLACE(endpoint, '?', '')) as question_mark_count
FROM config_lv1_api_list
WHERE endpoint LIKE '%?%'
ORDER BY question_mark_count DESC;
```

### I-14-E: FMP API ê¶Œí•œ í™•ì¸

```bash
# ìˆ˜ë™ í…ŒìŠ¤íŠ¸: aftermarket API ì ‘ê·¼ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
curl "https://financialmodelingprep.com/stable/aftermarket-trade?symbol=AAPL&apikey=YOUR_KEY"

# ì˜ˆìƒ ì‘ë‹µ:
# - 200 OK: API ì ‘ê·¼ ê°€ëŠ¥
# - 401 Unauthorized: API í‚¤ ë¬¸ì œ ë˜ëŠ” í”Œëœ ê¶Œí•œ ì—†ìŒ
# - 403 Forbidden: ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ë¶ˆê°€ (í”Œëœ ì—…ê·¸ë ˆì´ë“œ í•„ìš”)
```

---

## ëŸ°íƒ€ì„ ì´ìŠˆ ìš°ì„ ìˆœìœ„

| ID | ì´ìŠˆ | ìš°ì„ ìˆœìœ„ | ì˜í–¥ë„ | í•´ê²° ë‚œì´ë„ |
|----|------|----------|--------|-------------|
| I-13 | priceEodOHLC ì¶”ì¶œ ì‹¤íŒ¨ | ğŸ”´ ë†’ìŒ | ë†’ìŒ (OHLC ë°ì´í„° ì „ì²´) | ë‚®ìŒ (SQL ìˆ˜ì •) |
| I-14 | aftermarket API 401 | âš ï¸ ì¤‘ê°„ | ë‚®ìŒ (1ê°œ ë©”íŠ¸ë¦­) | ë‚®ìŒ (SQL ìˆ˜ì •) |
| I-12 | ë™ì  ê³„ì‚° ì½”ë“œ ì‹¤íŒ¨ | âš ï¸ ë‚®ìŒ | ì—†ìŒ (í´ë°± ì‘ë™) | ì¤‘ê°„ (ì½”ë“œ ì¬ì‘ì„±) |

**ê¶Œì¥ ì¡°ì¹˜ ìˆœì„œ**:
1. âœ… **I-13 ìš°ì„  í•´ê²°**: DB ìŠ¤í‚¤ë§ˆ í™•ì¸ â†’ response_key ìˆ˜ì •
2. âœ… **I-14 ê°„ë‹¨ ìˆ˜ì •**: endpoint URLì—ì„œ ë¶ˆí•„ìš”í•œ `?` ì œê±°
3. â¸ï¸ **I-12 ë³´ë¥˜**: í•˜ë“œì½”ë”© í´ë°±ìœ¼ë¡œ ì •ìƒ ì‘ë™ ì¤‘

---

## I-15: event_date_obj ë³€ìˆ˜ ìˆœì„œ ì˜¤ë¥˜

> **ë°œê²¬**: 2025-12-24 15:00 | **í•´ê²°**: 2025-12-24 15:30

### I-15-A: ë¬¸ì œ ë°œê²¬ ë° ìˆ˜ì •

**ì—ëŸ¬ ë¡œê·¸**:
```
[calculate_quantitative_metrics] Failed to fetch fmp-historical-price-eod-full: 
local variable 'event_date_obj' referenced before assignment
```

**ì›ì¸ ë¶„ì„**:
```python
# ì˜ëª»ëœ ìˆœì„œ (backend/src/services/valuation_service.py)

# 431-456ë¼ì¸: API í˜¸ì¶œ ë£¨í”„
for api_id in required_apis:
    params = {'ticker': ticker}
    if 'historical-price' in api_id or 'eod' in api_id:
        params['toDate'] = event_date_obj.strftime('%Y-%m-%d')  # âŒ 444ë¼ì¸: ì •ì˜ ì „ ì‚¬ìš©
    result = await fmp_client.call_api(api_id, params)

# 471-475ë¼ì¸: event_date_obj ì •ì˜
if isinstance(event_date, str):
    event_date_obj = datetime.fromisoformat(...).date()  # âŒ 471ë¼ì¸: ëŠ¦ì€ ì •ì˜
```

**ì ìš©ëœ ìˆ˜ì •**:
```python
# ì˜¬ë°”ë¥¸ ìˆœì„œ

# 430-438ë¼ì¸: event_date_objë¥¼ ë¨¼ì € ë³€í™˜ (MUST be done before API calls)
from datetime import datetime
if isinstance(event_date, str):
    event_date_obj = datetime.fromisoformat(event_date.replace('Z', '+00:00')).date()
elif hasattr(event_date, 'date'):
    event_date_obj = event_date.date()
else:
    event_date_obj = event_date

# 440-456ë¼ì¸: API í˜¸ì¶œ ë£¨í”„ (ì´ì œ ì•ˆì „í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥)
for api_id in required_apis:
    params = {'ticker': ticker}
    if 'historical-price' in api_id or 'eod' in api_id:
        params['fromDate'] = '2000-01-01'
        params['toDate'] = event_date_obj.strftime('%Y-%m-%d')  # âœ… ì •ì˜ í›„ ì‚¬ìš©
    result = await fmp_client.call_api(api_id, params)
```

**íŒŒì¼**: `backend/src/services/valuation_service.py:425-456`

---

## I-16: ë©”íŠ¸ë¦­ ì‹¤íŒ¨ ë””ë²„ê¹… ë¡œê·¸ ë¶€ì¬

> **ë°œê²¬**: 2025-12-24 16:00 | **í•´ê²°**: 2025-12-24 17:00

### I-16-A: ì‹¤íŒ¨ ì´ìœ  ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„

**ê¸°ì¡´ ë¡œê·¸** (ì´ìœ  ì—†ìŒ):
```
[MetricEngine] âœ— priceEodOHLC = None (source: api_field)
[MetricEngine] âœ— apicYoY = None (source: aggregation)
```

**ê°œì„ ëœ ë¡œê·¸** (ì´ìœ  í¬í•¨):
```
[MetricEngine] âœ— priceEodOHLC = None (source: api_field) | reason: No data from API 'fmp-historical-price-eod-full'
[MetricEngine] âœ— apicYoY = None (source: aggregation) | reason: Base metric 'additionalPaidInCapital' is None
```

**êµ¬í˜„ ì½”ë“œ** (`backend/src/services/metric_engine.py:272-326`):
```python
def _calculate_metric_with_reason(
    self, metric, api_data, calculated_values
) -> tuple:
    """Calculate metric with failure reason tracking."""
    source = metric.get('source')
    
    if source == 'api_field':
        value = self._calculate_api_field(metric, api_data)
        if value is None:
            api_list_id = metric.get('api_list_id')
            if not api_list_id:
                return None, "Missing api_list_id"
            elif api_list_id not in api_data or not api_data.get(api_list_id):
                return None, f"No data from API '{api_list_id}'"
            else:
                return None, f"Field extraction failed from '{api_list_id}'"
        return value, None
    # ... (aggregation, expression ì²˜ë¦¬)
```

**ì‹¤íŒ¨ ì´ìœ  ë¶„ë¥˜í‘œ**:

| Source | ì‹¤íŒ¨ ì´ìœ  | ì„¤ëª… |
|--------|----------|------|
| **api_field** | Missing api_list_id | configì— api_list_id ì—†ìŒ |
| | No data from API 'xxx' | API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ì‘ë‹µ |
| | Field extraction failed | response_key í•„ë“œ ë§¤í•‘ ì‹¤íŒ¨ |
| **aggregation** | Missing base_metric | configì— base_metric ì—†ìŒ |
| | Base metric 'xxx' is None | ì˜ì¡´ ë©”íŠ¸ë¦­ì´ NULL |
| | Transform 'xxx' returned None | aggregation í•¨ìˆ˜ê°€ NULL ë°˜í™˜ |
| **expression** | Missing dependencies: xxx | ì˜ì¡´ ë©”íŠ¸ë¦­ ëˆ„ë½ ë˜ëŠ” NULL |
| | Expression evaluation returned None | ìˆ˜ì‹ ê³„ì‚° ê²°ê³¼ NULL |

**íŒŒì¼**: `backend/src/services/metric_engine.py:241-326`

---

## I-17: ë¡œê·¸ í˜•ì‹ N/A ê³¼ë‹¤ ì¶œë ¥

> **ë°œê²¬**: 2025-12-24 17:00 | **í•´ê²°**: 2025-12-24 18:00

### I-17-A: ì¡°ê±´ë¶€ ë¡œê·¸ í¬ë§· êµ¬í˜„

**ë¬¸ì œ ìƒí™©**:
```
[N/A | N/A] | elapsed=0ms | progress=N/A | eta=0ms | rate=N/A | batch=N/A | counters=N/A | warn=[] | [API Response] fmp-aftermarket-trade -> HTTP 200
```

**ì ìš©ëœ ìˆ˜ì •** (`backend/src/services/utils/logging_utils.py:15-91`):
```python
def format(self, record: logging.LogRecord) -> str:
    # Check if this log has structured data
    has_structured_data = hasattr(record, 'endpoint') and record.endpoint != 'N/A'
    
    # If no structured data, use simple format
    if not has_structured_data:
        message = record.getMessage()
        return message  # âœ… N/A ì—†ì´ ê¹”ë”í•˜ê²Œ ì¶œë ¥
    
    # ... êµ¬ì¡°í™”ëœ í¬ë§· ì²˜ë¦¬
```

**ê°œì„ ëœ ì¶œë ¥**:
- **ë‹¨ìˆœ ë¡œê·¸** (ì„¸ë¶€ ì •ë³´): `[API Response] fmp-aftermarket-trade -> HTTP 200`
- **êµ¬ì¡°í™”ëœ ë¡œê·¸** (ì£¼ìš” ë‹¨ê³„): `[POST /backfillEventsTable | process_events] elapsed=5000ms | progress=10/30(33%) | ...`

**ë¬¸ì„œ**: `backend/LOGGING_GUIDE.md`

**íŒŒì¼**: `backend/src/services/utils/logging_utils.py:15-91`

---

## I-18: priceEodOHLC Schema Array Type ë¬¸ì œ

> **ë°œê²¬**: 2025-12-25 10:00 | **í•´ê²°**: 2025-12-25 11:30

### I-18-A: ë¬¸ì œ ë¶„ì„

**ì—ëŸ¬ ë¡œê·¸**:
```
[MetricEngine] Failed to calculate priceEodOHLC: unhashable type: 'list'
```

**ì—ëŸ¬ ìœ„ì¹˜**: `metric_engine.py:74` - `api_ids.add(api_list_id)`

**ì›ì¸**:
- DBì—ì„œ `config_lv1_api_list.schema`ê°€ `[{}]` (array)ë¡œ ì €ì¥ë¨
- Pythonì˜ `set()`ì— listë¥¼ ì¶”ê°€í•  ìˆ˜ ì—†ìŒ (unhashable)
- 19ê°œ API ì¤‘ `fmp-historical-price-eod-full`ë§Œ array type

### I-18-B: ê²€ì¦ SQL

```sql
-- ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸: diagnose_priceEodOHLC_issue.sql

-- 1. ëª¨ë“  API ìŠ¤í‚¤ë§ˆ íƒ€ì… í™•ì¸
SELECT 
    api,
    jsonb_typeof(schema) as schema_type,
    CASE WHEN jsonb_typeof(schema) = 'array' THEN 'âŒ ARRAY' ELSE 'âœ… OBJECT' END as status
FROM config_lv1_api_list
ORDER BY schema_type DESC;

-- ê²°ê³¼: 19ê°œ ì¤‘ 1ê°œë§Œ array
```

### I-18-C: ìˆ˜ì • SQL

```sql
-- ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸: fix_priceEodOHLC_array_types.sql

UPDATE config_lv1_api_list
SET schema = '{
    "symbol": "ticker",
    "date": "date",
    "open": "float",
    "high": "float",
    "low": "float",
    "close": "float",
    "adjClose": "float",
    "volume": "integer",
    "unadjustedVolume": "integer",
    "change": "float",
    "changePercent": "float",
    "vwap": "float",
    "label": "string",
    "changeOverTime": "float"
}'::jsonb
WHERE api = 'fmp-historical-price-eod-full'
  AND jsonb_typeof(schema) = 'array';
```

**íŒŒì¼ ëª©ë¡**:
- `backend/scripts/diagnose_priceEodOHLC_issue.sql`
- `backend/scripts/fix_priceEodOHLC_array_types.sql`
- `backend/scripts/verify_all_api_schemas.sql`
- `backend/scripts/EXECUTE_FIX_SEQUENCE.sql`

---

## I-19: ë©”íŠ¸ë¦­ ë¡œê·¸ Truncation ë¬¸ì œ

> **ë°œê²¬**: 2025-12-25 12:00 | **í•´ê²°**: 2025-12-25 13:00

### I-19-A: ìŠ¤ë§ˆíŠ¸ í¬ë§·íŒ… êµ¬í˜„

**ë¬¸ì œ**:
```
[MetricEngine] âœ“ priceEodOHLC = [{'low': 15.48, 'high': 16.37, 'open': 15.65, 'clo
                                                                              ^^^^ ì˜ë¦¼!
```

**ì›ì¸**: `str(value)[:50]` í•˜ë“œì½”ë”©

**ì ìš©ëœ ìˆ˜ì •** (`backend/src/services/metric_engine.py:258-271`):
```python
def _format_value_for_log(self, value) -> str:
    """Format metric value for logging with smart truncation."""
    if isinstance(value, list):
        if len(value) > 0:
            first_item = str(value[0])
            if len(first_item) > 100:
                first_item = first_item[:100] + "..."
            return f"[{first_item}, ...] ({len(value)} items)"
        else:
            return "[]"
    else:
        value_str = str(value)
        if len(value_str) > 150:
            return value_str[:150] + "..."
        return value_str
```

**ê°œì„ ëœ ì¶œë ¥**:
```
[MetricEngine] âœ“ priceEodOHLC = [{'low': 15.48, 'high': 16.37, 'open': 15.65, 'close': 16.2}, ...] (1082 items) (source: api_field)
```

**íš¨ê³¼**:
- âœ… ë¡œê·¸ ë…¸ì´ì¦ˆ 83% ê°ì†Œ (6ì¤„ â†’ 1ì¤„)
- âœ… `close` ê°’ ì™„ì „ í‘œì‹œ
- âœ… ì´ ê°œìˆ˜ í‘œì‹œ
- âœ… 150ì ì œí•œ (ì´ì „ 50ì â†’ 150ì)

**íŒŒì¼**: `backend/src/services/metric_engine.py:258-271`

---

## I-20: POST /backfillEventsTable ì„±ëŠ¥ ê°œì„ 

> **ë°œê²¬**: 2025-12-25 14:00 | **í•´ê²°**: 2025-12-25 18:00

### I-20-A: ë³µí•© ì „ëµ êµ¬í˜„

**ë¬¸ì œ**: 136,954ê°œ ì´ë²¤íŠ¸ ì²˜ë¦¬ì— 76ì‹œê°„ ì†Œìš” (ìˆœì°¨ ì²˜ë¦¬)

**í•´ê²° ì „ëµ**:
1. Ticker ê·¸ë£¹í™” â†’ API í˜¸ì¶œ 96% ê°ì†Œ
2. ë³‘ë ¬ ì²˜ë¦¬ â†’ ì²˜ë¦¬ ì†ë„ 10ë°° í–¥ìƒ
3. DB ë°°ì¹˜ ì“°ê¸° â†’ ì¿¼ë¦¬ 96% ê°ì†Œ

### I-20-B: Ticker ê·¸ë£¹í™”

```python
# backend/src/services/valuation_service.py
def group_events_by_ticker(events: List[Dict]) -> Dict[str, List[Dict]]:
    """Group events by ticker for batch processing."""
    grouped = defaultdict(list)
    for event in events:
        grouped[event['ticker']].append(event)
    return dict(grouped)

# 136,954 ì´ë²¤íŠ¸ â†’ ~5,000 ticker ê·¸ë£¹
```

### I-20-C: Ticker ë°°ì¹˜ ì²˜ë¦¬

```python
async def process_ticker_batch(pool, ticker, ticker_events, metrics_by_domain, overwrite):
    """Process all events for a single ticker in batch."""
    batch_updates = []
    
    # ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬ (API ìºì‹± í™œìš©)
    for event in ticker_events:
        quant = await calculate_quantitative_metrics(pool, ticker, event['event_date'], ...)
        qual = await calculate_qualitative_metrics(pool, ticker, event['event_date'], ...)
        batch_updates.append({
            'event_id': event['id'],
            'value_quantitative': quant.get('value'),
            'value_qualitative': qual.get('value'),
            # ...
        })
    
    # ë°°ì¹˜ DB ì—…ë°ì´íŠ¸
    await batch_update_event_valuations(pool, batch_updates, overwrite)
    return {'ticker': ticker, 'processed': len(batch_updates)}
```

### I-20-D: DB ë°°ì¹˜ ì—…ë°ì´íŠ¸

```python
# backend/src/database/queries/metrics.py
async def batch_update_event_valuations(pool, updates, overwrite):
    """Batch update event valuations using PostgreSQL UNNEST."""
    async with pool.acquire() as conn:
        await conn.execute("""
            WITH batch_data AS (
                SELECT * FROM UNNEST(
                    $1::uuid[],
                    $2::jsonb[],
                    $3::jsonb[],
                    $4::text[]
                ) AS t(event_id, value_quant, value_qual, status)
            )
            UPDATE txn_events e
            SET 
                value_quantitative = COALESCE(b.value_quant, e.value_quantitative),
                value_qualitative = COALESCE(b.value_qual, e.value_qualitative),
                status = b.status
            FROM batch_data b
            WHERE e.id = b.event_id
        """, event_ids, quant_values, qual_values, statuses)
```

### I-20-E: ë³‘ë ¬ ì²˜ë¦¬

```python
# calculate_valuations() ì¬êµ¬ì„±
async def calculate_valuations(pool, metrics_by_domain, overwrite, ...):
    # Phase 3: Ticker ê·¸ë£¹í™”
    ticker_groups = group_events_by_ticker(events)
    
    # Phase 4: ë³‘ë ¬ ì²˜ë¦¬
    TICKER_CONCURRENCY = 10  # 10ê°œ ticker ë™ì‹œ ì²˜ë¦¬
    semaphore = asyncio.Semaphore(TICKER_CONCURRENCY)
    
    async def process_with_semaphore(ticker, ticker_events):
        async with semaphore:
            return await process_ticker_batch(pool, ticker, ticker_events, ...)
    
    tasks = [process_with_semaphore(t, evts) for t, evts in ticker_groups.items()]
    results = await asyncio.gather(*tasks, return_exceptions=True)
```

### I-20-F: ì„±ëŠ¥ ê°œì„  ê²°ê³¼

| í•­ëª© | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| API í˜¸ì¶œ | 136,954 | ~5,000 | 96% â†“ |
| DB ì¿¼ë¦¬ | 136,954 | ~5,000 | 96% â†“ |
| ì²˜ë¦¬ ë°©ì‹ | ìˆœì°¨ | ë³‘ë ¬ (10 ticker) | - |
| **ì†Œìš” ì‹œê°„** | **76 ì‹œê°„** | **0.5-1 ì‹œê°„** | **99% â†“** |

**íŒŒì¼**:
- `backend/src/services/valuation_service.py`
- `backend/src/database/queries/metrics.py`

---

## I-21: priceEodOHLC domain ì„¤ì • ì˜¤ë¥˜

### I-21-A: ë¬¸ì œê°€ ëœ ìŠ¤í¬ë¦½íŠ¸ (ì‚­ì œë¨)

```python
# backend/fix_priceeodohlc_domain.py (ì‚­ì œë¨)
# ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ domainì„ ì˜ëª» ë³€ê²½í•¨

await conn.execute('''
    UPDATE config_lv2_metric
    SET domain = 'quantitative-momentum'  # âŒ ì˜ëª»ëœ ë³€ê²½
    WHERE id = 'priceEodOHLC'
''')
```

### I-21-B: ìˆ˜ì • SQL ìŠ¤í¬ë¦½íŠ¸

```sql
-- backend/scripts/fix_priceEodOHLC_domain_to_internal.sql

-- domainì„ internalë¡œ ë³µì›
UPDATE config_lv2_metric
SET domain = 'internal'
WHERE id = 'priceEodOHLC';

-- í™•ì¸
SELECT id, domain, source, api_list_id
FROM config_lv2_metric
WHERE id = 'priceEodOHLC';
```

### I-21-C: ê´€ë ¨ ì½”ë“œ (metric_engine.py)

```python
# backend/src/services/metric_engine.py:919-920
# domain='internal'ì¸ ê²½ìš° ê²°ê³¼ì—ì„œ ì œì™¸ë¨

def _group_by_domain(self, calculated_values, target_domains):
    for metric_name, value in calculated_values.items():
        domain = metric.get('domain', '')
        if not domain or domain == 'internal':
            continue  # âœ… internal ë„ë©”ì¸ì€ ê²°ê³¼ì— í¬í•¨ë˜ì§€ ì•ŠìŒ
```

---

## I-22: SQL ì˜ˆì•½ì–´ "position" ë¬¸ì œ

### I-22-A: ë¬¸ì œê°€ ëœ ì½”ë“œ

```python
# backend/src/database/queries/metrics.py

query = """
    UPDATE txn_events e
    SET ...
        position_quantitative = b.position_quantitative::position,  -- âŒ ì˜ˆì•½ì–´
        position_qualitative = b.position_qualitative::position,    -- âŒ ì˜ˆì•½ì–´
    ...
"""
```

### I-22-B: ìˆ˜ì •ëœ ì½”ë“œ

```python
# backend/src/database/queries/metrics.py

query = """
    UPDATE txn_events e
    SET ...
        position_quantitative = b.position_quantitative::"position",  -- âœ… ë”°ì˜´í‘œ ì¶”ê°€
        position_qualitative = b.position_qualitative::"position",    -- âœ… ë”°ì˜´í‘œ ì¶”ê°€
    ...
"""
```

**ìˆ˜ì • ìœ„ì¹˜**: ë¼ì¸ 284, 285, 315, 316 (ì´ 4ê³³)

---

## I-23: NULL ê°’ ë””ë²„ê¹… ë¡œê·¸ ê°œì„ 

### I-23-A: ë³€ê²½ ì „ ì½”ë“œ

```python
# backend/src/services/metric_engine.py

# DEBUG ë ˆë²¨ - ê¸°ë³¸ INFOì—ì„œ ë³´ì´ì§€ ì•ŠìŒ
logger.debug(f"[MetricEngine] âœ— {metric_name} = None (source: {metric.get('source')})")
```

### I-23-B: ë³€ê²½ í›„ ì½”ë“œ

```python
# backend/src/services/metric_engine.py:257-280

try:
    value, failure_reason = self._calculate_metric_with_reason(metric, api_data, calculated_values)
    calculated_values[metric_name] = value
    if value is not None:
        # ... ì„±ê³µ ë¡œê·¸ (DEBUG)
    else:
        # âœ… NULL ê°’ì€ INFO ë ˆë²¨ë¡œ ìƒì„¸ ë¡œê·¸
        domain = metric.get('domain', '')
        domain_suffix = domain.split('-', 1)[1] if '-' in domain else domain
        
        # íƒ€ê²Ÿ ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” ê²½ìš°ë§Œ ë¡œê·¸ ì¶œë ¥
        if domain != 'internal' and (not target_domains or domain_suffix in target_domains):
            reason_str = failure_reason if failure_reason else "Unknown reason"
            logger.info(f"[MetricEngine] âœ— NULL: {metric_name} | domain={domain_suffix} | reason={reason_str}")
```

### I-23-C: expression ì˜ì¡´ì„± ì¶”ì  ê°œì„ 

```python
# backend/src/services/metric_engine.py:333-350

elif source == 'expression':
    value = self._calculate_expression(metric, calculated_values)
    if value is None:
        # âœ… formulaì—ì„œ ì˜ì¡´ì„± ì¶”ì¶œ
        formula = metric.get('formula', '')
        dependencies = []
        for other_metric_name in self.metrics_by_name.keys():
            if other_metric_name in formula and other_metric_name != metric_name:
                dependencies.append(other_metric_name)
        
        # âœ… ê° ì˜ì¡´ì„±ì´ ì™œ ì—†ëŠ”ì§€ ìƒì„¸ ì¶”ì 
        missing = [d for d in dependencies if d not in calculated_values or calculated_values.get(d) is None]
        if missing:
            missing_details = []
            for d in missing:
                if d not in calculated_values:
                    missing_details.append(f"{d}(not_calculated)")
                else:
                    missing_details.append(f"{d}(=None)")
            return None, f"Missing deps: {', '.join(missing_details)} | formula: {formula}"
        else:
            return None, f"Expression eval failed | formula: {formula}"
```

### I-23-D: ì¶œë ¥ ì˜ˆì‹œ

```
[MetricEngine] âœ— NULL: PER | domain=valuation | reason=Missing deps: netIncomeTTM(=None) | formula: marketCap / netIncomeTTM
[MetricEngine] âœ— NULL: PBR | domain=valuation | reason=Missing deps: equityLatest(=None) | formula: marketCap / equityLatest
[MetricEngine] âœ— NULL: evEBITDA | domain=valuation | reason=Missing deps: ebitdaTTM(=None) | formula: (marketCap + netDebtLast) / ebitdaTTM
```

---

## I-24: price trends ì²˜ë¦¬ ì„±ëŠ¥ ìµœì í™”

### I-24-A: ê±°ë˜ì¼ ìºì‹± í•¨ìˆ˜

```python
# backend/src/services/utils/datetime_utils.py

async def get_trading_days_in_range(
    start_date: date,
    end_date: date,
    exchange: str,
    pool: asyncpg.Pool
) -> set:
    """
    ì „ì²´ ê¸°ê°„ì˜ ê±°ë˜ì¼ ì •ë³´ë¥¼ 1íšŒ DB ì¡°íšŒë¡œ ìºì‹œ.
    ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹œ DB ì¡°íšŒ ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œ ê³„ì‚° ê°€ëŠ¥.
    """
    # íœ´ì¥ì¼ì„ 1íšŒ ì¡°íšŒ
    holidays = await pool.fetch(
        """
        SELECT date FROM config_lv3_market_holidays 
        WHERE exchange = $1 
          AND date >= $2 
          AND date <= $3 
          AND is_fully_closed = true
        """,
        exchange, start_date, end_date
    )
    holiday_set = {h['date'] for h in holidays}
    
    # ê±°ë˜ì¼ ìƒì„± (ì£¼ë§ ë° íœ´ì¥ì¼ ì œì™¸)
    trading_days = set()
    current = start_date
    while current <= end_date:
        if current.weekday() < 5 and current not in holiday_set:
            trading_days.add(current)
        current += timedelta(days=1)
    
    return trading_days
```

### I-24-B: ìºì‹œ ê¸°ë°˜ dayOffset ê³„ì‚°

```python
# backend/src/services/utils/datetime_utils.py

def calculate_dayOffset_dates_cached(
    event_date: date,
    count_start: int,
    count_end: int,
    trading_days_set: set
) -> List[Tuple[int, date]]:
    """
    NO DB CALLS - ë¯¸ë¦¬ ìºì‹œëœ trading_days_set ì‚¬ìš©.
    
    Before: ì´ë²¤íŠ¸ë‹¹ ~29ê°œ DB ì¿¼ë¦¬ (dayOffset -14 ~ +14)
    After: ì´ë²¤íŠ¸ë‹¹ 0ê°œ DB ì¿¼ë¦¬
    """
    trading_days_sorted = sorted(trading_days_set)
    
    # base_date ì°¾ê¸° (event_date ì´í›„ ì²« ê±°ë˜ì¼)
    base_date = None
    for td in trading_days_sorted:
        if td >= event_date:
            base_date = td
            break
    
    if base_date is None:
        base_date = event_date
    
    # ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ offset ê³„ì‚° (O(1) ì—°ì‚°)
    base_idx = trading_days_sorted.index(base_date)
    
    results = []
    for offset in range(count_start, count_end + 1):
        target_idx = base_idx + offset
        if 0 <= target_idx < len(trading_days_sorted):
            results.append((offset, trading_days_sorted[target_idx]))
    
    return results
```

### I-24-C: generate_price_trends ìµœì í™”

```python
# backend/src/services/valuation_service.py

async def generate_price_trends(...):
    # âœ… 1. ì „ì²´ ê¸°ê°„ ê±°ë˜ì¼ ë¯¸ë¦¬ ìºì‹œ (1íšŒ DB ì¡°íšŒ)
    calendar_buffer = max(abs(count_start), abs(count_end)) * 2 + 30
    trading_range_start = min(all_event_dates) - timedelta(days=calendar_buffer)
    trading_range_end = max(all_event_dates) + timedelta(days=calendar_buffer)
    
    trading_days_set = await get_trading_days_in_range(
        trading_range_start, trading_range_end, 'NASDAQ', pool
    )
    
    # âœ… 2. ì´ë²¤íŠ¸ ì²˜ë¦¬ (DB ì¡°íšŒ ì—†ì´ ë©”ëª¨ë¦¬ ê³„ì‚°)
    batch_updates = []
    for event in events:
        dayoffset_dates = calculate_dayOffset_dates_cached(
            event_date, count_start, count_end, trading_days_set
        )
        # ... price_trend ìƒì„±
        batch_updates.append({...})
    
    # âœ… 3. ë°°ì¹˜ DB ì—…ë°ì´íŠ¸ (1íšŒ UPDATEë¡œ ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬)
    await conn.execute("""
        UPDATE txn_events e
        SET price_trend = b.price_trend::jsonb
        FROM (
            SELECT * FROM UNNEST($1::text[], $2::timestamptz[], $3::text[], $4::text[], $5::text[])
            AS t(ticker, event_date, source, source_id, price_trend)
        ) b
        WHERE e.ticker = b.ticker AND ...
    """, tickers, event_dates, sources, source_ids, price_trends)
```

### I-24-D: ì„±ëŠ¥ ê°œì„  ê²°ê³¼

| í•­ëª© | Before | After | ê°œì„ ìœ¨ |
|------|--------|-------|--------|
| ê±°ë˜ì¼ DB ì¡°íšŒ | ì´ë²¤íŠ¸ Ã— dayOffsetíšŒ | 1íšŒ | **99% â†“** |
| DB UPDATE | ì´ë²¤íŠ¸ë‹¹ 1íšŒ | ë°°ì¹˜ 1íšŒ | **99% â†“** |
| 53ê°œ ì´ë²¤íŠ¸ | ~10ë¶„ | ~10ì´ˆ | **98% â†“** |

**íŒŒì¼**:
- `backend/src/services/valuation_service.py`
- `backend/src/services/utils/datetime_utils.py`

---

## I-25: APIë³„ ê¸°ì¤€ ë‚ ì§œ ë¶ˆì¼ì¹˜ (Temporal Validity Mismatch)

> **ë°œê²¬**: 2025-12-27 | **í•´ê²°**: 2025-12-27 | **ìƒíƒœ**: âœ… ì™„ë£Œ

### I-25-A: ë¬¸ì œê°€ ëœ ì½”ë“œ

**íŒŒì¼**: `backend/src/services/valuation_service.py`

**ë¬¸ì œ ì½”ë“œ 1 - fmp-quote API í˜¸ì¶œ (ë¼ì¸ 96-113)**:
```python
async with FMPAPIClient() as fmp_client:
    # Fetch quantitative APIs
    for api_id in required_apis:
        try:
            params = {'ticker': ticker}
            
            if 'historical-price' in api_id or 'eod' in api_id:
                # Wide date range to cover all events
                params['fromDate'] = '2000-01-01'
                params['toDate'] = datetime.now().strftime('%Y-%m-%d')
            else:
                # âŒ fmp-quote APIë„ ì´ ë¶„ê¸°ë¡œ ë“¤ì–´ì˜´
                # âŒ period/limit íŒŒë¼ë¯¸í„°ê°€ ë¬´ì˜ë¯¸ (ìŠ¤ëƒ…ìƒ· API)
                params['period'] = 'quarter'
                params['limit'] = 100
            
            result = await fmp_client.call_api(api_id, params)
            ticker_api_cache[api_id] = result  # í˜„ì¬ ì‹œì  ë°ì´í„° ìºì‹œ
```

**ë¬¸ì œ ì½”ë“œ 2 - ë‚ ì§œ í•„í„°ë§ì—ì„œ ì œì™¸ (ë¼ì¸ 836-850)**:
```python
def _get_record_date(record: Dict[str, Any]):
    """Helper to extract and convert record date."""
    record_date = record.get('date')
    if not record_date:
        return None  # âŒ fmp-quote ì‘ë‹µì€ date í•„ë“œ ì—†ìŒ â†’ None ë°˜í™˜
    # ...

# calculate_quantitative_metrics_fast() ë‚´ë¶€:
api_data_filtered[api_id] = [
    r for r in records 
    if _get_record_date(r) is None or _get_record_date(r) <= event_date_obj
    # âŒ date ì—†ìœ¼ë©´ í•„í„°ë§ í†µê³¼ â†’ í˜„ì¬ ì‹œì  ë°ì´í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©
]
```

### I-25-B: ì˜í–¥ë°›ëŠ” ë©”íŠ¸ë¦­

**ì§ì ‘ ì˜í–¥**:
- `marketCap`: ì‹œê°€ì´ì•¡ (fmp-quoteì—ì„œ ì¶”ì¶œ)
- PER, PBR, PSR: marketCap ì˜ì¡´ ì§€í‘œ
- evEBITDA: Enterprise Value ì˜ì¡´ ì§€í‘œ

**ì˜ˆì‹œ - ì˜ëª»ëœ ê³„ì‚°**:
```
event_date: 2021-01-31
ì¬ë¬´ì œí‘œ: 2020 Q4 (netIncome = $100M)
marketCap: 2025ë…„ í˜„ì¬ ($50B) â† ì˜ëª»ë¨

PER = marketCap / netIncome = $50B / $100M = 500 â† ì™„ì „íˆ ì˜ëª»ëœ ê°’
ì‹¤ì œ 2021ë…„ PER = $5B / $100M = 50 (ê°€ì •)
```

### I-25-C: í•´ê²° ë°©ì•ˆ (ì±„íƒë¨ - êµ¬í˜„ ëŒ€ê¸°)

**âœ… ì±„íƒëœ ë°©ì•ˆ: FMP `historical-market-capitalization` API ì‚¬ìš©**

FMPì—ì„œ ê³¼ê±° marketCap ì¡°íšŒ APIë¥¼ ì œê³µí•¨:
- **API**: `/stable/historical-market-capitalization?symbol={ticker}&from={fromDate}&to={toDate}`
- **í•µì‹¬ ì¥ì **: `from`/`to` íŒŒë¼ë¯¸í„°ë¡œ ë‚ ì§œ ë²”ìœ„ íŠ¹ì • ê°€ëŠ¥
- **ì‘ë‹µ êµ¬ì¡°**:
```json
// API í˜¸ì¶œ: ?symbol=AAPL&from=2023-10-07&to=2023-10-11
[
  {"symbol": "AAPL", "date": "2023-10-11", "marketCap": 2788655387400},
  {"symbol": "AAPL", "date": "2023-10-10", "marketCap": 2766786621570},
  {"symbol": "AAPL", "date": "2023-10-09", "marketCap": 2776092479370}
  // 2023-10-07, 2023-10-08ì€ ì£¼ë§ì´ë¯€ë¡œ ë°ì´í„° ì—†ìŒ
]
```

**âš ï¸ ì£¼ì˜ì‚¬í•­**: ì£¼ë§/íœ´ì¥ì¼ì—ëŠ” ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ê±°ë˜ì¼ ì„ íƒ ë¡œì§ í•„ìš”

**êµ¬í˜„ ê³„íš:**

**1ë‹¨ê³„: config_lv1_api_listì— API ì¶”ê°€** (SQL ìŠ¤í¬ë¦½íŠ¸)
```sql
INSERT INTO config_lv1_api_list (id, api_service, api, schema, endpoint)
VALUES (
  'fmp-historical-market-capitalization',
  'financialmodelingprep',
  'https://financialmodelingprep.com/stable/historical-market-capitalization?symbol={ticker}&from={fromDate}&to={toDate}&apikey={apiKey}',
  '{"symbol": "ticker", "date": "date", "marketCap": "float"}'::jsonb,
  '/stable/historical-market-capitalization'
);
```

**2ë‹¨ê³„: config_lv2_metricì—ì„œ marketCap ë©”íŠ¸ë¦­ ìˆ˜ì •** (SQL ìŠ¤í¬ë¦½íŠ¸)
```sql
UPDATE config_lv2_metric
SET 
  api_list_id = 'fmp-historical-market-capitalization',
  response_key = 'marketCap'
WHERE id = 'marketCap';
```

**3ë‹¨ê³„: valuation_service.py ìˆ˜ì •** (Python)
```python
# process_ticker_batch() ë‚´ë¶€: historical-market-capitalizationë„ ë‚ ì§œ íŒŒë¼ë¯¸í„° í•„ìš”
if 'historical-price' in api_id or 'eod' in api_id or 'historical-market-cap' in api_id:
    params['fromDate'] = '2000-01-01'
    params['toDate'] = datetime.now().strftime('%Y-%m-%d')
```

**4ë‹¨ê³„: ê°€ì¥ ê°€ê¹Œìš´ ê±°ë˜ì¼ ì„ íƒ ë¡œì§ ì¶”ê°€** (Python)

ì£¼ë§/íœ´ì¥ì¼ì—ëŠ” marketCap ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ, event_date ì´í•˜ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œë¥¼ ì„ íƒí•´ì•¼ í•¨:

```python
def get_closest_market_cap(market_cap_data: List[Dict], event_date: date) -> Optional[float]:
    """
    event_date ì´í•˜ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œì˜ marketCap ë°˜í™˜.
    
    Args:
        market_cap_data: [{"date": "2023-10-11", "marketCap": 2788655387400}, ...]
        event_date: ì´ë²¤íŠ¸ ë‚ ì§œ
    
    Returns:
        ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œì˜ marketCap ë˜ëŠ” None
    
    ì˜ˆì‹œ:
        event_date = 2023-10-08 (ì¼ìš”ì¼)
        ë°ì´í„°: [2023-10-11, 2023-10-10, 2023-10-09, 2023-10-06, ...]
        ì„ íƒ: 2023-10-06 (event_date ì´í•˜ì˜ ê°€ì¥ ê°€ê¹Œìš´ ê±°ë˜ì¼)
    """
    if not market_cap_data:
        return None
    
    # date í•„ë“œ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ)
    sorted_data = sorted(
        market_cap_data,
        key=lambda x: x.get('date', ''),
        reverse=True
    )
    
    event_date_str = event_date.isoformat()
    
    # event_date ì´í•˜ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ ì°¾ê¸°
    for record in sorted_data:
        record_date = record.get('date', '')
        if record_date <= event_date_str:
            return record.get('marketCap')
    
    # ì—†ìœ¼ë©´ ê°€ì¥ ì˜¤ë˜ëœ ë°ì´í„° ë°˜í™˜ (fallback)
    if sorted_data:
        return sorted_data[-1].get('marketCap')
    
    return None
```

**5. fillPriceTrend_dateRange ì •ì±… í™œìš©**

API í˜¸ì¶œ ì‹œ ë‚ ì§œ ë²”ìœ„ë¥¼ ì •ì±…ì—ì„œ ê°€ì ¸ì™€ ì ìš©:

```python
# config_lv0_policyì—ì„œ ì •ì±… ë¡œë“œ
range_policy = await policies.get_price_trend_range_policy(pool)
count_start = range_policy['countStart']  # -14
count_end = range_policy['countEnd']      # +14

# event_date ê¸°ì¤€ ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
from_date = event_date + timedelta(days=count_start)  # -14ì¼
to_date = event_date + timedelta(days=count_end)      # +14ì¼

# API í˜¸ì¶œ
params = {
    'ticker': ticker,
    'fromDate': from_date.strftime('%Y-%m-%d'),
    'toDate': to_date.strftime('%Y-%m-%d')
}
```

**ì¥ì :**
- âœ… FMPì—ì„œ ê³µì‹ ì§€ì›í•˜ëŠ” API ì‚¬ìš©
- âœ… `from`/`to` íŒŒë¼ë¯¸í„°ë¡œ ì •í™•í•œ ë‚ ì§œ ë²”ìœ„ ì§€ì •
- âœ… ì£¼ë§/íœ´ì¥ì¼ ëŒ€ì‘: ê°€ì¥ ê°€ê¹Œìš´ ê±°ë˜ì¼ ìë™ ì„ íƒ
- âœ… ê¸°ì¡´ ì •ì±…(fillPriceTrend_dateRange) ì¬í™œìš©
- âœ… OHLC ë°ì´í„°ì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ìºì‹± ë° í•„í„°ë§ ê°€ëŠ¥

### I-25-D: êµ¬í˜„ SQL ìŠ¤í¬ë¦½íŠ¸

```sql
-- =====================================================
-- I-25 í•´ê²°: historical-market-capitalization API ì¶”ê°€
-- íŒŒì¼: backend/scripts/add_historical_market_cap_api.sql
-- =====================================================

-- 1. API ì„¤ì • ì¶”ê°€
INSERT INTO config_lv1_api_list (api, endpoint, api_service, schema, description)
VALUES (
  'fmp-historical-market-capitalization',
  '/stable/historical-market-capitalization?symbol={ticker}',
  'financialmodelingprep',
  '{
    "symbol": "ticker",
    "date": "date",
    "marketCap": "float"
  }'::jsonb,
  'Historical market capitalization data with date field for temporal validity'
)
ON CONFLICT (api) DO UPDATE SET
  endpoint = EXCLUDED.endpoint,
  schema = EXCLUDED.schema,
  description = EXCLUDED.description;

-- 2. marketCap ë©”íŠ¸ë¦­ì˜ api_list_id ë³€ê²½
UPDATE config_lv2_metric
SET 
  api_list_id = 'fmp-historical-market-capitalization',
  response_key = 'marketCap',
  description = 'Historical market cap (supports event_date filtering)'
WHERE id = 'marketCap';

-- 3. í™•ì¸ ì¿¼ë¦¬
SELECT id, api_list_id, response_key, domain
FROM config_lv2_metric
WHERE id = 'marketCap';

-- 4. marketCap ì˜ì¡´ ë©”íŠ¸ë¦­ í™•ì¸
SELECT id, formula, domain
FROM config_lv2_metric
WHERE formula LIKE '%marketCap%'
ORDER BY domain, id;
-- ì˜ˆìƒ ê²°ê³¼:
-- PER: marketCap / netIncomeTTM
-- PBR: marketCap / equityLatest
-- PSR: marketCap / revenueTTM
-- evEBITDA: (marketCap + netDebtLast) / ebitdaTTM
```

### I-25-E: Python ì½”ë“œ ìˆ˜ì • (âœ… êµ¬í˜„ ì™„ë£Œ)

**íŒŒì¼ 1: `backend/src/services/valuation_service.py`**

**ìˆ˜ì • 1 - process_ticker_batch() (ë¼ì¸ 100-107)**:
```python
# ìˆ˜ì • ì „:
if 'historical-price' in api_id or 'eod' in api_id:
    params['fromDate'] = '2000-01-01'
    params['toDate'] = datetime.now().strftime('%Y-%m-%d')

# ìˆ˜ì • í›„ (âœ… êµ¬í˜„ ì™„ë£Œ):
if 'historical-price' in api_id or 'eod' in api_id or 'historical-market-cap' in api_id:
    # I-25: fmp-historical-market-capitalizationë„ from/to íŒŒë¼ë¯¸í„° í•„ìš”
    params['fromDate'] = '2000-01-01'
    params['toDate'] = datetime.now().strftime('%Y-%m-%d')
```

**ìˆ˜ì • 2 - calculate_quantitative_metrics() (ë¼ì¸ 1013-1022)**:
```python
# ìˆ˜ì • ì „:
if 'historical-price' in api_id or 'eod' in api_id:
    params['fromDate'] = '2000-01-01'
    params['toDate'] = event_date_obj.strftime('%Y-%m-%d')

# ìˆ˜ì • í›„ (âœ… êµ¬í˜„ ì™„ë£Œ):
if 'historical-price' in api_id or 'eod' in api_id or 'historical-market-cap' in api_id:
    # I-25: fmp-historical-market-capitalizationë„ from/to íŒŒë¼ë¯¸í„° í•„ìš”
    params['fromDate'] = '2000-01-01'
    params['toDate'] = event_date_obj.strftime('%Y-%m-%d')
```

**íŒŒì¼ 2: `backend/src/services/metric_engine.py`**

**ìˆ˜ì • 3 - _calculate_api_field() (ë¼ì¸ 515-522)**:
```python
# ìˆ˜ì • ì „:
elif len(values) > 1:
    return values

# ìˆ˜ì • í›„ (âœ… êµ¬í˜„ ì™„ë£Œ):
elif len(values) > 1:
    # I-25: ì‹œê³„ì—´ ì‹œê°€ì´ì•¡ APIì˜ ê²½ìš° ê°€ì¥ ìµœê·¼ ë‚ ì§œ(ì²« ë²ˆì§¸)ì˜ ê°’ë§Œ ë°˜í™˜
    # historical-market-cap APIëŠ” event_date ì´ì „ì˜ ëª¨ë“  ë‚ ì§œë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ
    # ì²« ë²ˆì§¸ ê°’ì´ event_dateì— ê°€ì¥ ê°€ê¹Œìš´ marketCap
    if 'historical-market-cap' in api_list_id:
        logger.debug(f"[MetricEngine][I-25] Using latest marketCap from {len(values)} records")
        return values[0]
    return values
```

### I-25-F: DB ì„¤ì • ë°˜ì˜ (âœ… ì‚¬ìš©ì ì§ì ‘ ì™„ë£Œ)

**config_lv1_api_list í…Œì´ë¸”**:
| í•„ë“œ | ê°’ |
|------|-----|
| id | `fmp-historical-market-capitalization` |
| api_service | `financialmodelingprep` |
| api | `https://...?symbol={ticker}&from={fromDate}&to={toDate}&apikey={apiKey}` |
| schema | `{"date": "date", "symbol": "ticker", "marketCap": "float"}` |
| endpoint | `getQuantitiveValuation` |
| function2 | `getMarketCap` |

**config_lv2_metric í…Œì´ë¸”**:
| í•„ë“œ | ê°’ |
|------|-----|
| id | `marketCap` |
| source | `api_field` |
| api_list_id | `fmp-historical-market-capitalization` |
| response_key | `"marketCap"` |
| domain | `internal` |

---

## I-26: consensus_summary_cacheê°€ event_date ë¬´ì‹œ

> **ë°œê²¬**: 2025-12-27 | **í•´ê²°**: 2025-12-27 | **ìƒíƒœ**: âœ… ì™„ë£Œ

### I-26-A: ë¬¸ì œê°€ ëœ ì½”ë“œ

**íŒŒì¼**: `backend/src/services/valuation_service.py`

**ë¬¸ì œ ì½”ë“œ - consensus ìºì‹± (ë¼ì¸ 115-125)**:
```python
# Fetch qualitative API (consensus) ONCE for ticker
try:
    consensus_data = await fmp_client.call_api('fmp-price-target-consensus', {'ticker': ticker})
    if consensus_data:
        if isinstance(consensus_data, list) and len(consensus_data) > 0:
            consensus_summary_cache = consensus_data[0]  # âŒ í˜„ì¬ ì‹œì  ë°ì´í„°
        elif isinstance(consensus_data, dict):
            consensus_summary_cache = consensus_data
    logger.debug(f"[Ticker Batch] {ticker}: Consensus summary cached")
except Exception as e:
    logger.warning(f"[Ticker Batch] {ticker}: Consensus fetch skipped: {e}")
```

**ë¬¸ì œ ì½”ë“œ - consensus ì‚¬ìš© (ë¼ì¸ 1242-1254)**:
```python
# calculate_qualitative_metrics_fast() ë‚´ë¶€:

# Use CACHED consensus summary - NO API CALL!
target_median = 0
consensus_summary = consensus_summary_cache  # âŒ ëª¨ë“  ì´ë²¤íŠ¸ì— ë™ì¼í•œ ê°’ ì‚¬ìš©

if consensus_summary and isinstance(consensus_summary, dict):
    target_median = consensus_summary.get('targetMedian', 0)

value_qualitative = {
    'targetMedian': target_median,          # âŒ 2025ë…„ í˜„ì¬ ê°’
    'consensusSummary': consensus_summary,  # âŒ 2025ë…„ í˜„ì¬ ê°’
    'consensusSignal': consensus_signal     # âœ… evt_consensusì—ì„œ ê°€ì ¸ì™€ event_date ê¸°ì¤€
}
```

### I-26-B: ì˜í–¥ë°›ëŠ” í•„ë“œ

| í•„ë“œ | ì¶œì²˜ | ì‹œê°„ì  ìœ íš¨ì„± |
|------|------|---------------|
| `consensusSignal` | evt_consensus í…Œì´ë¸” | âœ… event_date ê¸°ì¤€ |
| `targetMedian` | fmp-price-target-consensus API | âŒ í˜„ì¬ ì‹œì  |
| `consensusSummary` | fmp-price-target-consensus API | âŒ í˜„ì¬ ì‹œì  |

### I-26-C: í•´ê²° ë°©ì•ˆ (âœ… ì˜µì…˜ A ì±„íƒ ë° êµ¬í˜„ ì™„ë£Œ)

**ì±„íƒëœ ì˜µì…˜ A: ê³¼ê±° consensus ì—†ìœ¼ë©´ NULL ì²˜ë¦¬**

**íŒŒì¼**: `backend/src/services/valuation_service.py`

**êµ¬í˜„ëœ ì½”ë“œ (ë¼ì¸ 1244-1287)**:
```python
# I-26: Check if event_date is historical (more than 7 days ago)
# FMP price-target-consensus API only provides current consensus, not historical
from datetime import timedelta
today = datetime.now().date()

# Convert event_date to date object
if isinstance(event_date, str):
    event_date_obj = datetime.fromisoformat(event_date.replace('Z', '+00:00')).date()
elif hasattr(event_date, 'date'):
    event_date_obj = event_date.date()
else:
    event_date_obj = event_date

is_historical_event = event_date_obj < (today - timedelta(days=7))

# Use CACHED consensus summary - NO API CALL!
# But only for recent events (within 7 days)
if is_historical_event:
    # I-26: Historical events should not use current consensus data
    target_median = None
    consensus_summary = None
    consensus_meta = {
        'dataAvailable': False,
        'reason': 'Historical event - FMP API only provides current consensus',
        'event_date': event_date_obj.isoformat(),
        'threshold_days': 7
    }
    logger.debug(f"[QualitativeMetrics][I-26] Skipping consensus for historical event {event_date_obj}")
else:
    # Recent event - use cached consensus data
    target_median = 0
    consensus_summary = consensus_summary_cache
    consensus_meta = {
        'dataAvailable': True,
        'fetchDate': today.isoformat()
    }
    
    if consensus_summary and isinstance(consensus_summary, dict):
        target_median = consensus_summary.get('targetMedian', 0)

# value_qualitative êµ¬ì„±
value_qualitative = {
    'targetMedian': target_median,
    'consensusSummary': consensus_summary,
    'consensusSignal': consensus_signal,
    '_meta': consensus_meta  # âœ… ë°ì´í„° ê°€ìš©ì„± ì •ë³´ ì¶”ê°€
}
```

**ë³€ê²½ ìš”ì•½**:
| í•­ëª© | Before | After |
|------|--------|-------|
| ê³¼ê±° ì´ë²¤íŠ¸ (7ì¼+) | í˜„ì¬ consensus ì ìš© âŒ | NULL + `_meta` ëª…ì‹œ âœ… |
| ìµœê·¼ ì´ë²¤íŠ¸ (7ì¼ë‚´) | í˜„ì¬ consensus ì ìš© | í˜„ì¬ consensus ì ìš© + `_meta` ì¶”ê°€ âœ… |
| íˆ¬ëª…ì„± | ì—†ìŒ | `_meta.dataAvailable`, `_meta.reason` âœ… |

**ì˜µì…˜ B: evt_consensus í…Œì´ë¸”ì—ì„œ ê³¼ê±° ë°ì´í„° ê³„ì‚°**
```python
# evt_consensus í…Œì´ë¸”ì˜ event_date ì´ì „ ë ˆì½”ë“œë“¤ë¡œ consensus ê³„ì‚°
async def calculate_historical_consensus(pool, ticker, event_date):
    """
    event_date ì‹œì ì˜ ì»¨ì„¼ì„œìŠ¤ ê³„ì‚°.
    evt_consensusì—ì„œ event_date ì´ì „ ìµœê·¼ ë ˆì½”ë“œë“¤ ì§‘ê³„.
    """
    rows = await pool.fetch("""
        SELECT price_target
        FROM evt_consensus
        WHERE ticker = $1 AND event_date <= $2
        ORDER BY event_date DESC
        LIMIT 10
    """, ticker, event_date)
    
    if not rows:
        return None
    
    targets = [r['price_target'] for r in rows if r['price_target']]
    if not targets:
        return None
    
    return {
        'targetMedian': statistics.median(targets),
        'targetHigh': max(targets),
        'targetLow': min(targets),
        'targetConsensus': statistics.mean(targets),
        'numberOfAnalysts': len(targets),
        '_meta': {
            'calcType': 'historical',
            'basedOnRecords': len(targets),
            'event_date': event_date.isoformat()
        }
    }
```

**ì˜µì…˜ C: _metaì— timestamp ëª…ì‹œ**
```python
value_qualitative = {
    'targetMedian': target_median,
    'consensusSummary': consensus_summary,
    'consensusSignal': consensus_signal,
    '_meta': {
        'targetMedian_fetchDate': datetime.now().isoformat(),  # ì–¸ì œ ê°€ì ¸ì˜¨ ê°’ì¸ì§€ ëª…ì‹œ
        'targetMedian_isHistorical': False  # ê³¼ê±° ê°’ì´ ì•„ë‹˜ì„ ëª…ì‹œ
    }
}
```

---

## I-27: priceTrend í‹°ì»¤ë³„ 1íšŒ í˜¸ì¶œ í™•ì¸

> **ë°œê²¬**: 2025-12-27 | **ìƒíƒœ**: âœ… í™•ì¸ ì™„ë£Œ

### I-27-A: ê²€ì¦ ê²°ê³¼

**íŒŒì¼**: `backend/src/services/valuation_service.py`

**ì •ìƒ ì‘ë™ í™•ì¸ - í‹°ì»¤ë³„ OHLC ìºì‹± (ë¼ì¸ 1570-1601)**:
```python
# Fetch OHLC data for all tickers
ohlc_cache = {}
async with FMPAPIClient() as fmp_client:
    # âœ… í‹°ì»¤ë³„ë¡œ 1íšŒë§Œ í˜¸ì¶œ
    for ticker, (fetch_start, fetch_end) in ohlc_ranges.items():
        logger.info(f"Fetching OHLC for {ticker} from {fetch_start} to {fetch_end}")

        # âœ… ì „ì²´ ë‚ ì§œ ë²”ìœ„ë¥¼ í•œ ë²ˆì— ì¡°íšŒ
        ohlc_data = await fmp_client.get_historical_price_eod(
            ticker,
            fetch_start.isoformat(),
            fetch_end.isoformat()
        )

        # âœ… ë‚ ì§œë³„ë¡œ ì¸ë±ì‹±í•˜ì—¬ ìºì‹œ
        ohlc_by_date = {}
        for record in ohlc_data:
            record_date = record.get('date')
            if record_date:
                ohlc_by_date[record_date] = record

        ohlc_cache[ticker] = ohlc_by_date  # âœ… ìºì‹œ ì €ì¥
```

**ì •ìƒ ì‘ë™ í™•ì¸ - ì´ë²¤íŠ¸ë³„ ìºì‹œ ì¡°íšŒ (ë¼ì¸ 1648-1675)**:
```python
for idx, event in enumerate(events):
    ticker = event['ticker']
    event_date = event['event_date']
    
    # âœ… ìºì‹œì—ì„œ ì¡°íšŒ (API í˜¸ì¶œ ì—†ìŒ)
    for dayoffset, target_date in dayoffset_dates:
        date_str = target_date.isoformat()
        ohlc = ohlc_cache.get(ticker, {}).get(date_str)  # âœ… O(1) ì¡°íšŒ
        
        if ohlc:
            price_trend.append({
                'dayOffset': dayoffset,
                'targetDate': date_str,
                'open': float(ohlc.get('open')),
                'high': float(ohlc.get('high')),
                'low': float(ohlc.get('low')),
                'close': float(ohlc.get('close'))
            })
```

### I-27-B: ì„±ëŠ¥ ë¶„ì„

| í•­ëª© | ì„¤ëª… |
|------|------|
| API í˜¸ì¶œ íšŸìˆ˜ | í‹°ì»¤ ìˆ˜ (N) |
| ìºì‹œ ì¡°íšŒ | ì´ë²¤íŠ¸ Ã— dayOffset (O(1)) |
| ë©”ëª¨ë¦¬ ì‚¬ìš© | í‹°ì»¤ë‹¹ ~3ë…„ OHLC ë°ì´í„° (~750 ë ˆì½”ë“œ) |

**ê²°ë¡ **: ìµœì í™”ëœ êµ¬í˜„ìœ¼ë¡œ ì¶”ê°€ ì¡°ì¹˜ ë¶ˆí•„ìš”.

---

## I-28: ì¬ë¬´ì œí‘œ TTM ê³„ì‚°ì˜ ì‹œê°„ì  ìœ íš¨ì„± í™•ì¸

> **ë°œê²¬**: 2025-12-27 | **ìƒíƒœ**: âœ… í™•ì¸ ì™„ë£Œ

### I-28-A: ì ê²€ ìš”ì²­ ë‚´ìš©

ì‚¬ìš©ì ìš”ì²­: event_date ê¸°ì¤€ìœ¼ë¡œ ì¬ë¬´ì œí‘œ TTM ê³„ì‚°ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ í™•ì¸.

**ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤**:
- event_date = 2024-12-22
- TTM ê³„ì‚°ì— ì‚¬ìš©í•´ì•¼ í•  ë¶„ê¸°: 2024-09-28, 2024-06-29, 2024-03-30, 2023-12-30
- 2024-12-28 ë¶„ê¸°ëŠ” event_date ì´í›„ì´ë¯€ë¡œ **ì œì™¸ë˜ì–´ì•¼ í•¨**

### I-28-B: ì½”ë“œ ë¶„ì„ ê²°ê³¼ (ì •ìƒ ì‘ë™)

**1ë‹¨ê³„: ë‚ ì§œ í•„í„°ë§ (valuation_service.py:847-850)**

```python
# calculate_quantitative_metrics_fast() ë‚´ë¶€
api_data_filtered[api_id] = [
    r for r in records 
    if _get_record_date(r) is None or _get_record_date(r) <= event_date_obj
    # âœ… event_date ì´ì „ì˜ ë¶„ê¸°ë§Œ í¬í•¨
    # âœ… 2024-12-28 > 2024-12-22 ì´ë¯€ë¡œ ì œì™¸ë¨
]
```

**2ë‹¨ê³„: netIncome ê°’ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (metric_engine.py:501-522)**

```python
# _calculate_api_field() ë‚´ë¶€
values = []
for record in api_response:  # í•„í„°ë§ëœ ì‘ë‹µ (ìµœì‹ ìˆœ ì •ë ¬ ìœ ì§€)
    value = record.get(field_key)  # field_key = 'netIncome'
    if value is not None:
        values.append(self._convert_value(value))

# ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜: [Q4ê°’, Q3ê°’, Q2ê°’, Q1ê°’, ...]
return values
```

**3ë‹¨ê³„: TTM í•©ì‚° (metric_engine.py:689-722)**

```python
def _ttm_sum_or_scaled(self, quarterly_values, params):
    window = params.get('window', 4)  # ê¸°ë³¸ê°’ 4ë¶„ê¸°
    
    # âœ… ìµœê·¼ 4ê°œ ë¶„ê¸° ì„ íƒ
    recent_quarters = quarterly_values[:window]
    
    # âœ… í•©ì‚°
    total = sum(recent_quarters)
    
    return total
```

### I-28-C: ê²€ì¦ ì˜ˆì‹œ

```
API ì›ë³¸ ì‘ë‹µ (fmp-income-statement, ìµœì‹ ìˆœ):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ date        â”‚ netIncome      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2025-09-27  â”‚ 27,466,000,000 â”‚  â† event_date ì´í›„ (ì œì™¸)
â”‚ 2025-06-28  â”‚ 23,434,000,000 â”‚  â† event_date ì´í›„ (ì œì™¸)
â”‚ 2025-03-29  â”‚ 24,780,000,000 â”‚  â† event_date ì´í›„ (ì œì™¸)
â”‚ 2024-12-28  â”‚ 36,330,000,000 â”‚  â† event_date ì´í›„ (ì œì™¸)
â”‚ 2024-09-28  â”‚ 14,736,000,000 â”‚  âœ… í¬í•¨ (Q4 2024)
â”‚ 2024-06-29  â”‚ 21,448,000,000 â”‚  âœ… í¬í•¨ (Q3 2024)
â”‚ 2024-03-30  â”‚ 23,636,000,000 â”‚  âœ… í¬í•¨ (Q2 2024)
â”‚ 2023-12-30  â”‚ 33,916,000,000 â”‚  âœ… í¬í•¨ (Q1 2024)
â”‚ ...         â”‚ ...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

event_date = 2024-12-22 ì ìš© í›„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ date        â”‚ netIncome      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2024-09-28  â”‚ 14,736,000,000 â”‚  âœ… TTM ê³„ì‚°ì— í¬í•¨
â”‚ 2024-06-29  â”‚ 21,448,000,000 â”‚  âœ… TTM ê³„ì‚°ì— í¬í•¨
â”‚ 2024-03-30  â”‚ 23,636,000,000 â”‚  âœ… TTM ê³„ì‚°ì— í¬í•¨
â”‚ 2023-12-30  â”‚ 33,916,000,000 â”‚  âœ… TTM ê³„ì‚°ì— í¬í•¨
â”‚ ...         â”‚ ...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

netIncomeTTM ê³„ì‚°:
= 14,736,000,000 + 21,448,000,000 + 23,636,000,000 + 33,916,000,000
= 93,736,000,000 âœ…
```

### I-28-D: ê²°ë¡ 

| í•­ëª© | ìƒíƒœ | ì„¤ëª… |
|------|------|------|
| ë‚ ì§œ í•„í„°ë§ | âœ… ì •ìƒ | `_get_record_date(r) <= event_date_obj` ì¡°ê±´ |
| ì •ë ¬ ìœ ì§€ | âœ… ì •ìƒ | FMP API ì‘ë‹µì€ ìµœì‹ ìˆœ, í•„í„°ë§ í›„ì—ë„ ìœ ì§€ |
| TTM í•©ì‚° | âœ… ì •ìƒ | `quarterly_values[:4]`ë¡œ ìµœê·¼ 4ë¶„ê¸° ì„ íƒ |

**ì¶”ê°€ ì¡°ì¹˜ ë¶ˆí•„ìš”** - í˜„ì¬ êµ¬í˜„ì´ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•©ë‹ˆë‹¤.

---

## I-29: evt_consensus 2ë‹¨ê³„ ê³„ì‚° ë¯¸ì‹¤í–‰

> **ë°œê²¬**: 2025-12-30 | **ìƒíƒœ**: âœ… ë°˜ì˜ë¨

### I-29-A: ë¬¸ì œ í™•ì¸ (DB ë°ì´í„°)

**evt_consensus í…Œì´ë¸” í™•ì¸ ê²°ê³¼**: ëª¨ë“  ë ˆì½”ë“œì˜ `price_target_prev`, `price_when_posted_prev`, `direction`ì´ NULL

**RGTI í‹°ì»¤ ì˜ˆì‹œ** (David Williams / Williams Trading íŒŒí‹°ì…˜):
```
event_date       | price_target | price_target_prev | direction | ì˜ˆìƒê°’
-----------------|--------------|-------------------|-----------|--------
2023-08-11       | 4            | NULL              | NULL      | NULL (ì²« ë²ˆì§¸)
2025-08-13       | 20           | NULL              | NULL      | prev=4, direction=up
2025-10-07       | 50           | NULL              | NULL      | prev=20, direction=up
2025-11-11       | 40           | NULL              | NULL      | prev=50, direction=down
```

### I-29-B: ì›ì¸ ë¶„ì„

**ë¬¸ì œ**: GET /sourceData?mode=consensusì˜ **2ë‹¨ê³„ ê³„ì‚°ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ**

**ì •ìƒ íë¦„**:
1. **1ë‹¨ê³„ (Raw Upsert)**: APIì—ì„œ consensus ë°ì´í„° fetch â†’ evt_consensusì— ì €ì¥
   - price_target, price_when_posted ë“± ê¸°ë¡ âœ… ì™„ë£Œë¨
2. **2ë‹¨ê³„ (ë³€ê²½ ê°ì§€ ë° ê¸°ë¡)**: íŒŒí‹°ì…˜ë³„(ticker, analyst_name, analyst_company)ë¡œ prev/direction ê³„ì‚°
   - price_target_prev, price_when_posted_prev, direction ê³„ì‚° âŒ **ë¯¸ì‹¤í–‰**

**2ë‹¨ê³„ ê³„ì‚° ë¡œì§ ìœ„ì¹˜**: `backend/src/services/source_data_service.py:266-305`

```python
# get_consensus() í•¨ìˆ˜ ë‚´ 2ë‹¨ê³„ ë¡œì§
for partition in target_partitions:
    ticker, analyst_name, analyst_company = partition
    
    # íŒŒí‹°ì…˜ ë‚´ ì´ë²¤íŠ¸ë“¤ì„ event_date DESCë¡œ ì •ë ¬
    events = await consensus.select_partition_events(pool, ticker, analyst_name, analyst_company)
    
    for i, event in enumerate(events):
        if i < len(events) - 1:
            prev_event = events[i + 1]
            price_target_prev = prev_event['price_target']
            price_when_posted_prev = prev_event['price_when_posted']
            
            # direction ê³„ì‚°
            if event['price_target'] > price_target_prev:
                direction = 'up'
            elif event['price_target'] < price_target_prev:
                direction = 'down'
            else:
                direction = None
```

### I-29-C: í•´ê²° ë°©ë²• (êµ¬í˜„ ì™„ë£Œ)

**calc_mode=calculation ëª¨ë“œ ì¶”ê°€**: API í˜¸ì¶œ ì—†ì´ 2ë‹¨ê³„ ê³„ì‚°ë§Œ ìˆ˜í–‰

```bash
# ì „ì²´ íŒŒí‹°ì…˜ ì¬ê³„ì‚° (API í˜¸ì¶œ ì—†ìŒ, ê¸°ì¡´ ë°ì´í„° ê¸°ë°˜)
GET /sourceData?mode=consensus&calc_mode=calculation&calc_scope=all

# íŠ¹ì • í‹°ì»¤ë§Œ ì¬ê³„ì‚°
GET /sourceData?mode=consensus&calc_mode=calculation&calc_scope=ticker&tickers=RGTI,AAPL

# ë‚ ì§œ ë²”ìœ„ ë‚´ ì´ë²¤íŠ¸ê°€ ìˆëŠ” íŒŒí‹°ì…˜ë§Œ ì¬ê³„ì‚°
GET /sourceData?mode=consensus&calc_mode=calculation&calc_scope=event_date_range&from_date=2023-01-01&to_date=2025-12-31
```

**ìˆ˜ì •ëœ íŒŒì¼**:
1. `backend/src/services/source_data_service.py:177-260` - calc_mode=calculation ë¡œì§ ì¶”ê°€
2. `backend/src/models/request_models.py:81-99` - calc_mode ê²€ì¦ ë¡œì§ ìˆ˜ì •
3. `QUICKSTART.md` - calc_mode=calculation ì‚¬ìš©ë²• ë¬¸ì„œí™”

```python
async def get_consensus(...):
    # calc_mode=calculation: Skip Phase 1 (API calls), only run Phase 2
    if calc_mode == 'calculation':
        logger.info("[get_consensus] calc_mode=calculation: Skipping Phase 1, running Phase 2 only")
        
        phase1_elapsed = 0
        phase1_counters = Counters()
        affected_partitions = []
        
        # Phase 2 will use calc_scope to determine target partitions
    else:
        # Phase 1: Raw Upsert (API í˜¸ì¶œ)
        ...
    
    # Phase 2: Change Detection
    if calc_mode in ('maintenance', 'calculation'):
        target_partitions = await determine_phase2_partitions(...)
```

### I-29-D: ì½”ë“œ í™•ì¸ (ì •ìƒ)

**íŒŒì¼**: `backend/src/services/valuation_service.py:1207-1211`

```python
# âœ… ì½”ë“œëŠ” ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ ì‘ì„±ë˜ì–´ ìˆìŒ
price_target = consensus_data.get('price_target')
price_when_posted = consensus_data.get('price_when_posted')
price_target_prev = consensus_data.get('price_target_prev')
price_when_posted_prev = consensus_data.get('price_when_posted_prev')  # âœ… ì¡´ì¬í•¨
direction = consensus_data.get('direction')
```

**ê²°ë¡ **: ì½”ë“œ ë¬¸ì œê°€ ì•„ë‹Œ, **2ë‹¨ê³„ ê³„ì‚° ë¯¸ì‹¤í–‰ìœ¼ë¡œ ì¸í•œ DB ë°ì´í„° ë¬¸ì œ**

---

## I-30: ë©”íŠ¸ë¦­ë³„ ì›ì²œ ë‚ ì§œ ì¶”ì  (ì˜µì…˜ B ì±„íƒ)

> **ë°œê²¬**: 2025-12-30 | **ìƒíƒœ**: âœ… í•´ê²°ë¨ (2025-12-31)

### I-30-A: í˜„ì¬ ì¶œë ¥ (ë¬¸ì œ)

```json
{
  "valuation": {
    "_meta": {
      "count": 4,
      "calcType": "TTM_fullQuarter",
      "date_range": null
    },
    "PER": -31.19,
    "PBR": 9.29
  }
}
```

**ë¬¸ì œì **:
1. PER = marketCap / netIncomeTTM ê³„ì‚° ì‹œ:
   - marketCapì´ **ì–´ë–¤ ë‚ ì§œì˜ ê°’**ì¸ì§€ ì•Œ ìˆ˜ ì—†ìŒ
   - netIncomeTTMì´ **ì–´ë–¤ ë¶„ê¸°ë“¤ì˜ í•©**ì¸ì§€ ì•Œ ìˆ˜ ì—†ìŒ
2. ê³„ì‚°ëœ ê°’ì´ ì˜¬ë°”ë¥¸ ì‹œì ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ”ì§€ **ê²€ì¦ ë¶ˆê°€ëŠ¥**

### I-30-B: ì±„íƒëœ êµ¬ì¡° (ì˜µì…˜ B)

**ë©”íŠ¸ë¦­ë³„ ìƒì„¸ _sources êµ¬ì¡°**:

```json
{
  "valuation": {
    "PER": {
      "value": -31.19,
      "_sources": {
        "marketCap": {
          "api": "fmp-historical-market-capitalization",
          "date": "2025-08-13",
          "value": 8029534478.0
        },
        "netIncomeTTM": {
          "api": "fmp-income-statement",
          "quarters": ["2024-09-30", "2024-12-31", "2025-03-31", "2025-06-30"],
          "values": [100000000, 120000000, 110000000, -130000000],
          "total": -257000000
        }
      }
    },
    "PBR": {
      "value": 9.29,
      "_sources": {
        "marketCap": {
          "api": "fmp-historical-market-capitalization",
          "date": "2025-08-13",
          "value": 8029534478.0
        },
        "equityLatest": {
          "api": "fmp-balance-sheet",
          "date": "2025-06-30",
          "value": 864000000
        }
      }
    }
  }
}
```

### I-30-C: êµ¬í˜„ íë¦„

**1ë‹¨ê³„: ì›ì²œ ë©”íŠ¸ë¦­ ê³„ì‚° ì‹œ ë‚ ì§œ ì •ë³´ ìˆ˜ì§‘**

**íŒŒì¼**: `backend/src/services/metric_engine.py`

```python
# _calculate_api_field() ìˆ˜ì •
def _calculate_api_field(self, metric, api_data):
    """API í•„ë“œì—ì„œ ê°’ ì¶”ì¶œ ì‹œ ë‚ ì§œ ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜"""
    api_list_id = metric.get('api_list_id')
    api_response = api_data.get(api_list_id, [])
    
    # ... ê¸°ì¡´ ê°’ ì¶”ì¶œ ë¡œì§ ...
    
    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
    source_info = {
        'api': api_list_id,
        'value': extracted_value
    }
    
    # API ì‘ë‹µì— date í•„ë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if api_response and isinstance(api_response, list) and len(api_response) > 0:
        if 'date' in api_response[0]:
            source_info['date'] = api_response[0]['date']
    
    return extracted_value, source_info  # íŠœí”Œë¡œ ë°˜í™˜
```

**2ë‹¨ê³„: TTM í•©ì‚° ì‹œ ë¶„ê¸° ì •ë³´ ìˆ˜ì§‘**

```python
# _ttm_sum_or_scaled() ìˆ˜ì •
def _ttm_sum_or_scaled(self, quarterly_values, params, api_response=None):
    """TTM í•©ì‚° ì‹œ ì‚¬ìš©ëœ ë¶„ê¸° ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜"""
    window = params.get('window', 4)
    recent_quarters = quarterly_values[:window]
    total = sum(recent_quarters)
    
    source_info = {
        'total': total,
        'values': recent_quarters
    }
    
    # ë¶„ê¸° ë‚ ì§œ ì¶”ì¶œ
    if api_response:
        quarters = [r.get('date') for r in api_response[:window] if r.get('date')]
        source_info['quarters'] = quarters
    
    return total, source_info  # íŠœí”Œë¡œ ë°˜í™˜
```

**3ë‹¨ê³„: expression ë©”íŠ¸ë¦­ ê³„ì‚° ì‹œ ì˜ì¡´ì„± _sources ìˆ˜ì§‘**

```python
# _calculate_expression() ìˆ˜ì •
def _calculate_expression(self, metric, calculated_values):
    """expression ê³„ì‚° ì‹œ ì˜ì¡´ì„±ë“¤ì˜ _sources ìˆ˜ì§‘"""
    formula = metric.get('formula', '')  # ì˜ˆ: "marketCap / netIncomeTTM"
    
    # ì˜ì¡´ì„± ì¶”ì¶œ
    dependencies = self._extract_dependencies(formula)
    
    # ê° ì˜ì¡´ì„±ì˜ _sources ìˆ˜ì§‘
    sources = {}
    for dep in dependencies:
        if dep in self.metric_sources:
            sources[dep] = self.metric_sources[dep]
    
    # ê³„ì‚° ìˆ˜í–‰
    result = eval(formula, calculated_values)
    
    return result, sources  # íŠœí”Œë¡œ ë°˜í™˜
```

**4ë‹¨ê³„: ìµœì¢… ì¶œë ¥ êµ¬ì¡° ë³€í™˜**

```python
# _group_by_domain() ìˆ˜ì •
def _group_by_domain(self, calculated_values, metric_sources):
    """ë©”íŠ¸ë¦­ì„ ë„ë©”ì¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  {value, _sources} êµ¬ì¡°ë¡œ ë³€í™˜"""
    result = {}
    
    for metric_name, value in calculated_values.items():
        metric = self.metrics_by_name.get(metric_name)
        domain = metric.get('domain', '')
        
        if domain == 'internal':
            continue
        
        domain_key = domain.split('-', 1)[1] if '-' in domain else domain
        
        if domain_key not in result:
            result[domain_key] = {}
        
        # ë©”íŠ¸ë¦­ ê°’ì„ {value, _sources} êµ¬ì¡°ë¡œ ì €ì¥
        sources = metric_sources.get(metric_name)
        if sources:
            result[domain_key][metric_name] = {
                'value': value,
                '_sources': sources
            }
        else:
            result[domain_key][metric_name] = {'value': value}
    
    return result
```

### I-30-D: ì˜í–¥ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ìˆ˜ì • ë‚´ìš© |
|------|-----------|
| `metric_engine.py` | _calculate_api_field, _ttm_sum_or_scaled, _calculate_expression ìˆ˜ì • |
| `valuation_service.py` | API ì‘ë‹µ ë‚ ì§œ ì •ë³´ ì „ë‹¬, ì¶œë ¥ êµ¬ì¡° ë³€í™˜ |
| `config_lv2_metric` | (ë³€ê²½ ì—†ìŒ) |

### I-30-E: êµ¬í˜„ ì™„ë£Œ (2025-12-31)

**íŒŒì¼**: `backend/src/services/metric_engine.py`

**1. metric_sources ë”•ì…”ë„ˆë¦¬ ì¶”ê°€**:

```python
class MetricCalculationEngine:
    def __init__(self, ...):
        ...
        self.metric_sources = {}  # I-30: Track source metadata for each metric
```

**2. _calculate_api_field_with_source() í•¨ìˆ˜ ì¶”ê°€**:

```python
def _calculate_api_field_with_source(self, metric, api_data) -> tuple:
    """API ì‘ë‹µì—ì„œ ê°’ê³¼ ì†ŒìŠ¤ ì •ë³´ë¥¼ í•¨ê»˜ ì¶”ì¶œ"""
    value = self._calculate_api_field(metric, api_data)
    
    source_info = {
        'api': api_list_id,
        'type': 'api_field'
    }
    
    # API ì‘ë‹µì—ì„œ ë‚ ì§œ ì¶”ì¶œ
    if isinstance(api_response, list):
        dates = [record.get('date')[:10] for record in api_response if record.get('date')]
        source_info['dates'] = dates[:4]  # ìµœê·¼ 4ê°œ
        source_info['count'] = len(dates)
    
    return value, source_info
```

**3. _calculate_aggregation_with_source() í•¨ìˆ˜ ì¶”ê°€**:

```python
def _calculate_aggregation_with_source(self, metric, api_data, calculated_values) -> tuple:
    """Aggregation ê³„ì‚° ì‹œ ê¸°ë³¸ ë©”íŠ¸ë¦­ ì†ŒìŠ¤ ìƒì†"""
    value = self._calculate_aggregation(...)
    
    source_info = {
        'type': 'aggregation',
        'transform': aggregation_kind
    }
    
    # ê¸°ë³¸ ë©”íŠ¸ë¦­ ì†ŒìŠ¤ ìƒì†
    base_source = self.metric_sources.get(base_metric_id)
    if base_source:
        source_info['baseMetric'] = base_metric_id
        source_info.update(base_source)  # ë‚ ì§œ ì •ë³´ ë³µì‚¬
    
    return value, source_info
```

**4. _calculate_expression_with_source() í•¨ìˆ˜ ì¶”ê°€**:

```python
def _calculate_expression_with_source(self, metric, calculated_values) -> tuple:
    """Expression ê³„ì‚° ì‹œ ì˜ì¡´ì„±ë“¤ì˜ ì†ŒìŠ¤ ìˆ˜ì§‘"""
    value = self._calculate_expression(...)
    
    source_info = {
        'type': 'expression',
        'formula': formula,
        'dependencies': dependencies,
        'sources': {dep: self.metric_sources.get(dep) for dep in dependencies}
    }
    
    return value, source_info
```

**5. _group_by_domain() ìˆ˜ì • - _meta.sources ì¶”ê°€**:

```python
def _group_by_domain(self, calculated_values, target_domains):
    """ë„ë©”ì¸ë³„ ê·¸ë£¹í™” + _meta.sources í¬í•¨"""
    
    # ê° ë„ë©”ì¸ì˜ ë©”íŠ¸ë¦­ë³„ ì†ŒìŠ¤ ìˆ˜ì§‘
    for metric_name in result[domain_suffix]:
        source_info = self.metric_sources.get(metric_name)
        if source_info:
            domain_sources[metric_name] = source_info
    
    result[domain_suffix]['_meta'] = {
        'calcType': 'TTM_fullQuarter',
        'count': 4,
        'sources': domain_sources,  # âœ… ë©”íŠ¸ë¦­ë³„ ìƒì„¸ ì†ŒìŠ¤
        'dateRange': f"{min_date} ~ {max_date}"  # âœ… ë‚ ì§œ ë²”ìœ„ ìš”ì•½
    }
```

### I-30-F: ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "valuation": {
    "_meta": {
      "calcType": "TTM_fullQuarter",
      "count": 4,
      "dateRange": "2024-09-28 ~ 2025-08-13",
      "sources": {
        "PER": {
          "type": "expression",
          "formula": "marketCap / netIncomeTTM",
          "dependencies": ["marketCap", "netIncomeTTM"],
          "sources": {
            "marketCap": {
              "api": "fmp-historical-market-capitalization",
              "date": "2025-08-13"
            },
            "netIncomeTTM": {
              "api": "fmp-income-statement",
              "dates": ["2024-09-28", "2024-12-28", "2025-03-29", "2025-06-28"],
              "count": 4
            }
          }
        },
        "PBR": {
          "type": "expression",
          "formula": "marketCap / equityLatest",
          "dependencies": ["marketCap", "equityLatest"],
          "sources": {...}
        }
      }
    },
    "PER": -31.19,
    "PBR": 9.29,
    "PSR": 648.82,
    "evEBITDA": -25.36
  }
}
```

### I-30-G: ì£¼ì˜ì‚¬í•­

1. **ê¸°ì¡´ API í˜¸í™˜ì„±**: ê°’ ìì²´ëŠ” `{"PER": -31.19}` í˜•ì‹ ìœ ì§€, `_meta.sources`ì— ìƒì„¸ ì •ë³´ ì¶”ê°€
2. **ë°ì´í„° í¬ê¸° ì¦ê°€**: _meta.sources ì •ë³´ ì¶”ê°€ë¡œ JSON í¬ê¸° ì¦ê°€ (ì•½ 2-3KB per domain)
3. **ë‚´ë¶€ ë©”íŠ¸ë¦­ ì œì™¸**: domainì´ 'internal'ì¸ ì¤‘ê°„ ê³„ì‚° ë©”íŠ¸ë¦­ì€ sourcesì—ì„œ ì œì™¸

---

## I-31: targetSummary ê³„ì‚° (consensusSummary ëŒ€ì²´)

> **ë°œê²¬**: 2025-12-31 | **ìƒíƒœ**: âœ… í•´ê²°ë¨ (2025-12-31)

### I-31-A: ë¬¸ì œ ìƒí™©

**ê¸°ì¡´ êµ¬í˜„ì˜ í•œê³„**:

```json
// POST /backfillEventsTable ê²°ê³¼
{
  "value_qualitative": {
    "_meta": {
      "reason": "Historical event - FMP API only provides current consensus",
      "dataAvailable": false
    },
    "targetMedian": null,
    "consensusSummary": null,  // âŒ í•­ìƒ null (ê³¼ê±° ì´ë²¤íŠ¸)
    "consensusSignal": {...}
  }
}
```

**ì›ì¸**: fmp-price-target-consensus APIëŠ” í˜„ì¬ ì‹œì  ë°ì´í„°ë§Œ ë°˜í™˜

### I-31-B: ì±„íƒëœ í•´ê²° ë°©ì•ˆ (Method B)

**ì‚¬ì „ ê³„ì‚° ë° ì €ì¥ ë°©ì‹**:

1. GET /sourceData?mode=consensusì—ì„œ Phase 3ë¡œ target_summary ê³„ì‚°
2. evt_consensus í…Œì´ë¸”ì— target_summary ì»¬ëŸ¼ ì €ì¥
3. POST /backfillEventsTableì—ì„œ ì €ì¥ëœ ê°’ ì½ê¸°

### I-31-C: DB ìŠ¤í‚¤ë§ˆ ë³€ê²½

```sql
-- evt_consensus í…Œì´ë¸”ì— target_summary ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE evt_consensus 
ADD COLUMN target_summary JSONB DEFAULT NULL;

-- ì¸ë±ìŠ¤ ì¶”ê°€ (ì„ íƒ)
CREATE INDEX idx_evt_consensus_target_summary 
ON evt_consensus USING GIN (target_summary);
```

### I-31-D: ì§‘ê³„ í•¨ìˆ˜ êµ¬í˜„

**íŒŒì¼**: `backend/src/database/queries/consensus.py`

```python
async def calculate_target_summary(
    pool: asyncpg.Pool, 
    ticker: str, 
    event_date: date
) -> Dict[str, Any]:
    """
    event_date ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±° consensus ë°ì´í„°ë¥¼ ì§‘ê³„í•˜ì—¬ targetSummary ìƒì„±
    
    ì§‘ê³„ ë²”ìœ„:
    - lastMonth: ìµœê·¼ 30ì¼
    - lastQuarter: ìµœê·¼ 90ì¼  
    - lastYear: ìµœê·¼ 365ì¼
    - allTime: ì „ì²´ ê¸°ê°„
    """
    query = """
    WITH date_ranges AS (
        SELECT 
            $2::date AS event_date,
            $2::date - INTERVAL '30 days' AS last_month,
            $2::date - INTERVAL '90 days' AS last_quarter,
            $2::date - INTERVAL '365 days' AS last_year
    ),
    aggregated AS (
        SELECT 
            -- Last Month
            AVG(CASE WHEN c.event_date >= dr.last_month THEN c.price_target END) AS last_month_avg,
            MIN(CASE WHEN c.event_date >= dr.last_month THEN c.price_target END) AS last_month_low,
            MAX(CASE WHEN c.event_date >= dr.last_month THEN c.price_target END) AS last_month_high,
            COUNT(CASE WHEN c.event_date >= dr.last_month THEN 1 END) AS last_month_count,
            -- Last Quarter
            AVG(CASE WHEN c.event_date >= dr.last_quarter THEN c.price_target END) AS last_quarter_avg,
            -- Last Year
            AVG(CASE WHEN c.event_date >= dr.last_year THEN c.price_target END) AS last_year_avg,
            -- All Time
            AVG(c.price_target) AS all_time_avg,
            MIN(c.price_target) AS all_time_low,
            MAX(c.price_target) AS all_time_high,
            COUNT(*) AS all_time_count,
            -- Publishers
            ARRAY_AGG(DISTINCT c.analyst_company) AS publishers
        FROM evt_consensus c, date_ranges dr
        WHERE c.ticker = $1
          AND c.event_date <= dr.event_date
    )
    SELECT * FROM aggregated;
    """
    
    async with pool.acquire() as conn:
        row = await conn.fetchrow(query, ticker, event_date)
        
    if not row or row['all_time_count'] == 0:
        return None
    
    return {
        'lastMonth': {
            'avg': float(row['last_month_avg']) if row['last_month_avg'] else None,
            'low': float(row['last_month_low']) if row['last_month_low'] else None,
            'high': float(row['last_month_high']) if row['last_month_high'] else None,
            'count': row['last_month_count']
        },
        'lastQuarter': {
            'avg': float(row['last_quarter_avg']) if row['last_quarter_avg'] else None
        },
        'lastYear': {
            'avg': float(row['last_year_avg']) if row['last_year_avg'] else None
        },
        'allTime': {
            'avg': float(row['all_time_avg']) if row['all_time_avg'] else None,
            'low': float(row['all_time_low']) if row['all_time_low'] else None,
            'high': float(row['all_time_high']) if row['all_time_high'] else None,
            'count': row['all_time_count'],
            'publishers': list(filter(None, row['publishers'] or []))
        },
        'calculatedAt': datetime.now().isoformat(),
        'eventDate': event_date.isoformat()
    }
```

### I-31-E: Phase 3 ì²˜ë¦¬ íë¦„

**íŒŒì¼**: `backend/src/services/source_data_service.py`

```python
# GET /sourceData?mode=consensus ì²˜ë¦¬ íë¦„
async def get_consensus(...):
    # Phase 1: API í˜¸ì¶œ (calc_mode=calculationì´ë©´ ìŠ¤í‚µ)
    if calc_mode != 'calculation':
        await fetch_from_fmp_api(...)
    
    # Phase 2: price_target_prev, price_when_posted_prev, direction ê³„ì‚°
    await calculate_prev_values(...)
    
    # Phase 3: target_summary ê³„ì‚° ë° ì €ì¥ (NEW!)
    for event in target_events:
        target_summary = await consensus.calculate_target_summary(
            pool, event['ticker'], event['event_date']
        )
        if target_summary:
            await consensus.update_consensus_phase3(pool, [
                {'id': event['id'], 'target_summary': target_summary}
            ])
```

### I-31-F: backfillEventsTableì—ì„œ ì½ê¸°

**íŒŒì¼**: `backend/src/services/valuation_service.py`

```python
async def calculate_qualitative_metrics_fast(...):
    # evt_consensusì—ì„œ target_summary ì¡°íšŒ
    consensus_data = await metrics.select_consensus_data(
        pool, ticker, event_date, source_id
    )
    
    target_summary = consensus_data.get('target_summary')  # ì‚¬ì „ ê³„ì‚°ëœ ê°’
    target_median = target_summary.get('allTime', {}).get('avg') if target_summary else None
    
    value_qualitative = {
        'targetMedian': target_median,
        'targetSummary': target_summary,  # âœ… consensusSummary ëŒ€ì²´
        'consensusSignal': consensus_signal,
        '_meta': {
            'dataAvailable': target_summary is not None,
            'source': 'evt_consensus (pre-calculated)'
        }
    }
```

### I-31-G: ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "value_qualitative": {
    "targetMedian": 25.5,
    "targetSummary": {
      "lastMonth": {
        "avg": 28.0,
        "low": 25.0,
        "high": 32.0,
        "count": 3
      },
      "lastQuarter": {
        "avg": 26.5
      },
      "lastYear": {
        "avg": 22.3
      },
      "allTime": {
        "avg": 25.5,
        "low": 15.0,
        "high": 35.0,
        "count": 12,
        "publishers": ["Williams Trading", "Needham", "Jefferies"]
      },
      "calculatedAt": "2025-12-31T10:30:00",
      "eventDate": "2025-08-13"
    },
    "consensusSignal": {
      "last": {"price_target": 20.0, "price_when_posted": 16.77},
      "prev": {"price_target": 4.0, "price_when_posted": 2.53},
      "delta": 16.0,
      "deltaPct": 400.0,
      "direction": "up"
    },
    "_meta": {
      "dataAvailable": true,
      "source": "evt_consensus (pre-calculated)"
    }
  }
}
```

### I-31-H: ì‚¬ìš© ë°©ë²•

```bash
# 1. ì „ì²´ consensus ë°ì´í„° ì¬ê³„ì‚° (Phase 2 + Phase 3)
GET /sourceData?mode=consensus&calc_mode=calculation&calc_scope=all

# 2. íŠ¹ì • í‹°ì»¤ë§Œ ì¬ê³„ì‚°
GET /sourceData?mode=consensus&calc_mode=calculation&calc_scope=ticker&tickers=RGTI,AAPL

# 3. ê¸°ì¡´ ê°’ ë®ì–´ì“°ê¸° (overwrite=true)
GET /sourceData?mode=consensus&calc_mode=calculation&calc_scope=all&overwrite=true

# 4. backfill ì‹¤í–‰ (target_summary ì½ê¸°)
POST /backfillEventsTable { "overwrite": true, "tickers": ["RGTI"] }
```

### I-31-I: ì˜í–¥ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|-----------|
| `database/queries/consensus.py` | calculate_target_summary(), update_consensus_phase3() ì¶”ê°€ |
| `services/source_data_service.py` | Phase 3 ë¡œì§ ì¶”ê°€ |
| `database/queries/metrics.py` | select_consensus_data()ì— target_summary í¬í•¨ |
| `services/valuation_service.py` | targetSummary ì½ê¸° ë¡œì§ |
| `evt_consensus` í…Œì´ë¸” | target_summary JSONB ì»¬ëŸ¼ ì¶”ê°€ |

---

## I-32: Log íŒ¨ë„ ë¦¬ì‚¬ì´ì¦ˆ ê¸°ëŠ¥

### I-32-A: ë¦¬ì‚¬ì´ì¦ˆ ìƒíƒœ ê´€ë¦¬

**íŒŒì¼**: `frontend/src/pages/RequestsPage.jsx`

```javascript
// RequestsPage ì»´í¬ë„ŒíŠ¸ì—ì„œ íŒ¨ë„ í¬ê¸° ìƒíƒœ ê´€ë¦¬
const [panelSize, setPanelSize] = useState(400); // ê¸°ë³¸ê°’: 400px

// íŒ¨ë„ ìœ„ì¹˜ ë³€ê²½ ì‹œ í¬ê¸° ì´ˆê¸°í™”
const handlePositionChange = useCallback((newPosition) => {
  setPanelPosition(newPosition);
  setPanelSize(newPosition === 'right' ? 480 : 400); // ìš°ì¸¡: 480px, í•˜ë‹¨: 400px
}, []);
```

### I-32-B: BottomPanel ë¦¬ì‚¬ì´ì¦ˆ í•¸ë“¤ëŸ¬

**íŒŒì¼**: `frontend/src/pages/RequestsPage.jsx`

```javascript
function BottomPanel({ ..., panelSize, onPanelResize }) {
  const [isResizing, setIsResizing] = useState(false);

  // ë§ˆìš°ìŠ¤ ë“œë˜ê·¸ ì´ë²¤íŠ¸ ì²˜ë¦¬
  const handleMouseDown = useCallback((e) => {
    e.preventDefault();
    setIsResizing(true);
  }, []);

  React.useEffect(() => {
    if (!isResizing) return;

    const handleMouseMove = (e) => {
      if (isRightPanel) {
        // ìš°ì¸¡ íŒ¨ë„: X ì¢Œí‘œ ê¸°ë°˜ ë„ˆë¹„ ê³„ì‚°
        const newWidth = Math.max(300, Math.min(800, window.innerWidth - e.clientX));
        onPanelResize(newWidth);
      } else {
        // í•˜ë‹¨ íŒ¨ë„: Y ì¢Œí‘œ ê¸°ë°˜ ë†’ì´ ê³„ì‚°
        const newHeight = Math.max(200, Math.min(600, window.innerHeight - e.clientY));
        onPanelResize(newHeight);
      }
    };

    const handleMouseUp = () => setIsResizing(false);

    document.addEventListener('mousemove', handleMouseMove);
    document.addEventListener('mouseup', handleMouseUp);

    return () => {
      document.removeEventListener('mousemove', handleMouseMove);
      document.removeEventListener('mouseup', handleMouseUp);
    };
  }, [isResizing, isRightPanel, onPanelResize]);

  // ë¦¬ì‚¬ì´ì¦ˆ í•¸ë“¤ ìŠ¤íƒ€ì¼
  const resizeHandleStyles = isRightPanel
    ? { position: 'absolute', top: 0, left: 0, width: '6px', height: '100%', cursor: 'ew-resize' }
    : { position: 'absolute', top: 0, left: 0, right: 0, height: '6px', cursor: 'ns-resize' };

  return (
    <div style={panelStyles}>
      {/* ë¦¬ì‚¬ì´ì¦ˆ í•¸ë“¤ */}
      <div
        style={resizeHandleStyles}
        onMouseDown={handleMouseDown}
        onMouseEnter={(e) => { e.currentTarget.style.backgroundColor = 'var(--accent-primary)'; }}
        onMouseLeave={(e) => { if (!isResizing) e.currentTarget.style.backgroundColor = 'transparent'; }}
      />
      {/* íŒ¨ë„ ë‚´ìš© */}
    </div>
  );
}
```

### I-32-C: ë™ì  íŒ¨ë„ í¬ê¸° ìŠ¤íƒ€ì¼

```javascript
const panelStyles = isRightPanel
  ? {
      position: 'fixed',
      top: headerHeight,
      right: 0,
      bottom: 0,
      width: `${panelSize}px`, // â† ë™ì  í¬ê¸°
      transition: isResizing ? 'none' : 'width 0.1s ease-out',
    }
  : {
      position: 'fixed',
      bottom: 0,
      left: 0,
      right: 0,
      height: `${panelSize}px`, // â† ë™ì  í¬ê¸°
      transition: isResizing ? 'none' : 'height 0.1s ease-out',
    };
```

---

## I-33: ë³¸ë¬¸ 80% ë„ˆë¹„ ë° ê°€ìš´ë° ì •ë ¬

### I-33-A: RequestsPage ë ˆì´ì•„ì›ƒ

**íŒŒì¼**: `frontend/src/pages/RequestsPage.jsx`

```javascript
// Wrapper: íŒ¨ë„ ì˜ì—­ì„ ì œì™¸í•œ ì‚¬ìš© ê°€ëŠ¥ ì˜ì—­
const getWrapperStyle = () => {
  const panelWidth = panelOpen ? panelSize : 48;
  
  if (panelPosition === 'right') {
    return {
      marginRight: `${panelWidth}px`, // íŒ¨ë„ ì˜ì—­ í™•ë³´
      transition: 'margin 0.1s ease-out',
      minHeight: '100vh',
    };
  } else {
    return {
      paddingBottom: panelOpen ? `${panelSize + 20}px` : '80px',
      transition: 'padding 0.1s ease-out',
    };
  }
};

// Content: ì‚¬ìš© ê°€ëŠ¥ ì˜ì—­ì˜ 80% ë„ˆë¹„, ê°€ìš´ë° ì •ë ¬
const getMainContentStyle = () => ({
  padding: 'var(--space-4)',
  width: '80%',
  maxWidth: '1400px',
  margin: '0 auto',
});

return (
  <>
    <div style={getWrapperStyle()}>
      <div style={getMainContentStyle()}>
        {/* ë³¸ë¬¸ ë‚´ìš© */}
      </div>
    </div>
    <BottomPanel ... />
  </>
);
```

### I-33-B: ë‹¤ë¥¸ í˜ì´ì§€ ê³µí†µ ìŠ¤íƒ€ì¼

**ì ìš© íŒŒì¼**:
- `frontend/src/pages/SetRequestsPage.jsx`
- `frontend/src/pages/ControlPage.jsx`
- `frontend/src/pages/ConditionGroupPage.jsx`
- `frontend/src/pages/DashboardPage.jsx`

```javascript
<div style={{ 
  padding: 'var(--space-4)', 
  width: '80%',           // 80% ë„ˆë¹„
  maxWidth: '1400px',     // ìµœëŒ€ ë„ˆë¹„ ì œí•œ
  margin: '0 auto'        // ê°€ìš´ë° ì •ë ¬
}}>
  {/* í˜ì´ì§€ ë‚´ìš© */}
</div>
```

---

## I-34: /setRequests API ë³€ê²½ ê¸°ëŠ¥ (Schema ê¸°ë°˜ ê²€ì¦)

### I-34-A: ì—”ë“œí¬ì¸íŠ¸ API ì„¤ì • êµ¬ì¡°

**íŒŒì¼**: `frontend/src/pages/SetRequestsPage.jsx`

```javascript
const ENDPOINT_CONFIG = {
  sourceData: {
    title: 'GET /sourceData',
    description: 'ì™¸ë¶€ API ë°ì´í„° ìˆ˜ì§‘',
    modes: {
      holiday: {
        description: 'ì‹œì¥ íœ´ì¥ì¼ ìˆ˜ì§‘',
        currentApiId: 'fmp-market-holidays',
        requiredKeys: ['year', 'date', 'exchange'],
        configKey: 'sourceData.holiday.apiId'
      },
      consensus: {
        description: 'ì• ë„ë¦¬ìŠ¤íŠ¸ ì»¨ì„¼ì„œìŠ¤ ìˆ˜ì§‘',
        currentApiId: 'fmp-price-target',
        requiredKeys: ['symbol', 'priceTarget', 'priceWhenPosted', 'analystName', 'analystCompany'],
        configKey: 'sourceData.consensus.apiId'
      },
      earning: {
        description: 'ì‹¤ì  ë°œí‘œ ìˆ˜ì§‘',
        currentApiId: 'fmp-earning-call-transcript',
        requiredKeys: ['symbol', 'date', 'content'],
        configKey: 'sourceData.earning.apiId'
      }
    }
  },
  backfillEventsTable: {
    title: 'POST /backfillEventsTable',
    description: 'Valuation ë©”íŠ¸ë¦­ ê³„ì‚°',
    phases: {
      incomeStatement: { ... },
      balanceSheet: { ... },
      marketCap: { ... },
      priceHistory: { ... }
    }
  }
};
```

### I-34-B: Schema ê¸°ë°˜ ê²€ì¦ í•¨ìˆ˜

```javascript
// API í˜¸ì¶œ ì—†ì´ config_lv1_api_list.schema í•„ë“œë¡œ ê²€ì¦
const validateSchemaKeys = (apiId, requiredKeys) => {
  const api = apiList.find(a => a.id === apiId);
  if (!api) {
    return { valid: false, error: `API '${apiId}' not found` };
  }

  // Schemaì—ì„œ í‚¤ ì¶”ì¶œ
  let schemaKeys = [];
  if (api.schema) {
    if (typeof api.schema === 'object') {
      schemaKeys = Object.keys(api.schema);
    } else if (typeof api.schema === 'string') {
      const parsed = JSON.parse(api.schema);
      schemaKeys = Object.keys(parsed);
    }
  }

  // í•„ìˆ˜ í‚¤ ê²€ì¦
  const missingKeys = requiredKeys.filter(key => !schemaKeys.includes(key));
  
  return {
    valid: missingKeys.length === 0,
    schemaKeys,
    requiredKeys,
    missingKeys,
    api
  };
};
```

### I-34-C: ë³€ê²½ ëª¨ë‹¬ UI

```javascript
{editingApi && (
  <div className="modal">
    <h3>API ë³€ê²½: {editingApi.modeKey}</h3>
    
    {/* í˜„ì¬ API */}
    <div>í˜„ì¬ API: {editingApi.currentApiId}</div>
    
    {/* í•„ìˆ˜ í‚¤ í‘œì‹œ */}
    <div>í•„ìˆ˜ ì‘ë‹µ í‚¤: {editingApi.requiredKeys.join(', ')}</div>
    
    {/* ìƒˆ API ì„ íƒ */}
    <select value={selectedNewApiId} onChange={...}>
      {apiList.map(api => (
        <option key={api.id} value={api.id}>
          [{api.api_service}] {api.id}
        </option>
      ))}
    </select>
    
    {/* ê²€ì¦ ê²°ê³¼ */}
    {validationResult && (
      <div className={validationResult.valid ? 'success' : 'error'}>
        {validationResult.valid 
          ? 'âœ… Schemaì— í•„ìˆ˜ í‚¤ê°€ ëª¨ë‘ ì¡´ì¬í•©ë‹ˆë‹¤' 
          : `âŒ ëˆ„ë½ëœ í‚¤: ${validationResult.missingKeys.join(', ')}`
        }
      </div>
    )}
    
    {/* ë²„íŠ¼ */}
    <button onClick={handleValidate}>ğŸ” Schema ê²€ì¦</button>
    <button onClick={handleSave} disabled={!validationResult?.valid}>
      ğŸ’¾ ì €ì¥
    </button>
  </div>
)}
```

### I-34-D: ì„¤ì • ì €ì¥

```javascript
const handleSave = async () => {
  if (!validationResult?.valid) return;

  // localStorageì— ì„¤ì • ì €ì¥ (ë°±ì—”ë“œ ì—°ë™ ê°€ëŠ¥)
  const savedConfig = JSON.parse(localStorage.getItem('endpointApiConfig') || '{}');
  savedConfig[editingApi.configKey] = selectedNewApiId;
  localStorage.setItem('endpointApiConfig', JSON.stringify(savedConfig));
  
  // UI ê°±ì‹ 
  setEndpointConfig(newConfig);
  setEditingApi(null);
};
```

### I-34-E: ì˜í–¥ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|-----------|
| `frontend/src/pages/SetRequestsPage.jsx` | ì „ë©´ ì¬ì‘ì„± - Schema ê¸°ë°˜ API ë³€ê²½ UI |
| `backend/src/routers/control.py` | GET /control/apiList ì—”ë“œí¬ì¸íŠ¸ (schema í¬í•¨ ì‘ë‹µ) |

---

## I-35: GET /sourceData ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ ê°œì„ 

### I-35-A: ê¸°ì¡´ ìˆœì°¨ ì²˜ë¦¬ ë¬¸ì œ ì½”ë“œ

**íŒŒì¼**: `backend/src/services/source_data_service.py`

```python
# âŒ ê¸°ì¡´: ìˆœì°¨ ì²˜ë¦¬ (í‹°ì»¤ë³„ 1íšŒì”©)
all_consensus = []
async with FMPAPIClient() as fmp_client:
    for ticker in ticker_list:  # 5000ê°œ í‹°ì»¤
        consensus_list = await fmp_client.get_price_target_consensus(ticker)
        if consensus_list:
            all_consensus.extend(consensus_list)
# â†’ 5000íšŒ ìˆœì°¨ í˜¸ì¶œ, ê° 1ì´ˆ ê°€ì • ì‹œ ~83ë¶„ ì†Œìš”
```

```python
# âŒ ê¸°ì¡´: ë‚ ì§œ ë²”ìœ„ë³„ ìˆœì°¨ ì²˜ë¦¬
for from_date, to_date in date_ranges:  # ~260ê°œ ë²”ìœ„ (past=true)
    earnings_data = await fmp_client.get_earnings_calendar(...)
    all_earnings.extend(earnings_data)
# â†’ 260íšŒ ìˆœì°¨ í˜¸ì¶œ, ì•½ 4ë¶„ ì†Œìš”
```

### I-35-B: ê°œì„ ëœ ë³‘ë ¬ ì²˜ë¦¬ ì½”ë“œ (mode=consensus)

```python
import asyncio

# ë™ì‹œì„± ì„¤ì • (Rate limit ê³ ë ¤)
API_CONCURRENCY = 10  # ë™ì‹œ API í˜¸ì¶œ ìˆ˜
API_BATCH_SIZE = 50   # ì§„í–‰ë¥  ë¡œê¹… ë°°ì¹˜ í¬ê¸°

# Phase 1: Parallel API calls with Semaphore
all_consensus = []
completed_tickers = 0
failed_tickers = 0
semaphore = asyncio.Semaphore(API_CONCURRENCY)
results_lock = asyncio.Lock()

async def fetch_ticker_consensus(fmp_client: FMPAPIClient, ticker: str):
    nonlocal completed_tickers, failed_tickers
    async with semaphore:  # Rate limit ì œì–´
        try:
            consensus_list = await fmp_client.get_price_target_consensus(ticker)
            async with results_lock:
                if consensus_list:
                    all_consensus.extend(consensus_list)
                completed_tickers += 1
                
                # ì§„í–‰ë¥  ë¡œê¹…
                if completed_tickers % API_BATCH_SIZE == 0:
                    progress_pct = (completed_tickers / total_tickers) * 100
                    elapsed = time.time() - phase1_start
                    rate = completed_tickers / elapsed
                    eta = (total_tickers - completed_tickers) / rate
                    
                    logger.info(
                        f"[Phase 1] progress={completed_tickers}/{total_tickers}"
                        f"({progress_pct:.1f}%) | rate={rate:.1f}/s | ETA: {eta:.0f}s"
                    )
        except Exception as e:
            async with results_lock:
                failed_tickers += 1
                completed_tickers += 1
            logger.warning(f"Failed to fetch consensus for {ticker}: {e}")

# ë³‘ë ¬ ì‹¤í–‰
async with FMPAPIClient() as fmp_client:
    tasks = [fetch_ticker_consensus(fmp_client, ticker) for ticker in ticker_list]
    await asyncio.gather(*tasks)  # ëª¨ë“  ì‘ì—… ë³‘ë ¬ ì‹¤í–‰
```

### I-35-C: ê°œì„ ëœ ë³‘ë ¬ ì²˜ë¦¬ ì½”ë“œ (mode=earning)

```python
async def fetch_range_earnings(fmp_client: FMPAPIClient, from_date: date, to_date: date):
    nonlocal completed_ranges, failed_ranges
    async with semaphore:
        try:
            earnings_data = await fmp_client.get_earnings_calendar(
                from_date.isoformat(),
                to_date.isoformat()
            )
            async with results_lock:
                if earnings_data:
                    all_earnings.extend(earnings_data)
                completed_ranges += 1
                
                if completed_ranges % API_BATCH_SIZE == 0:
                    # ì§„í–‰ë¥  ë¡œê¹… (ë™ì¼ íŒ¨í„´)
                    ...
        except Exception as e:
            async with results_lock:
                failed_ranges += 1
                completed_ranges += 1
            logger.warning(f"Failed to fetch earnings for {from_date} ~ {to_date}: {e}")

async with FMPAPIClient() as fmp_client:
    tasks = [fetch_range_earnings(fmp_client, fr, to) for fr, to in date_ranges]
    await asyncio.gather(*tasks)
```

### I-35-D: í•µì‹¬ ì„¤ê³„ íŒ¨í„´ (POST /backfillEventsTable ì°¸ì¡°)

```python
# 1. Semaphoreë¡œ ë™ì‹œì„± ì œì–´
semaphore = asyncio.Semaphore(API_CONCURRENCY)  # 10ê°œ ë™ì‹œ

# 2. Lockìœ¼ë¡œ ê³µìœ  ë°ì´í„° ë³´í˜¸
results_lock = asyncio.Lock()

# 3. gatherë¡œ ë³‘ë ¬ ì‹¤í–‰
await asyncio.gather(*tasks)

# 4. ê°œë³„ ì‹¤íŒ¨ ì‹œ ê³„ì† ì§„í–‰
except Exception as e:
    failed_count += 1  # ì‹¤íŒ¨ ì¹´ìš´íŠ¸ë§Œ ì¦ê°€
    continue  # ë‹¤ìŒ ì‘ì—… ê³„ì†

# 5. ì§„í–‰ë¥ /ETA ë¡œê¹…
if completed % BATCH_SIZE == 0:
    rate = completed / elapsed
    eta = remaining / rate
    logger.info(f"progress={completed}/{total} | ETA: {eta}s")
```

### I-35-E: ì„±ëŠ¥ ê°œì„  ìš”ì•½

| ëª¨ë“œ | ëŒ€ìƒ | Before | After | ê°œì„ ìœ¨ |
|------|------|--------|-------|--------|
| consensus | 5000 í‹°ì»¤ | ~83ë¶„ (ìˆœì°¨) | ~8ë¶„ (10ê°œ ë³‘ë ¬) | **90% â†“** |
| earning (past=true) | ~260 ë²”ìœ„ | ~4ë¶„ (ìˆœì°¨) | ~30ì´ˆ (10ê°œ ë³‘ë ¬) | **87% â†“** |

### I-35-F: Rate Limit ê³ ë ¤ì‚¬í•­

| API Provider | Rate Limit | ê¶Œì¥ ë™ì‹œì„± |
|--------------|------------|-------------|
| FMP (Free) | 300/ë¶„ | 5 |
| FMP (Starter) | 750/ë¶„ | 10 |
| FMP (Premium) | 3000/ë¶„ | 30 |

```python
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥
API_CONCURRENCY = int(os.getenv('FMP_CONCURRENCY', 10))
```

### I-35-G: ì˜í–¥ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|-----------|
| `backend/src/services/source_data_service.py` | asyncio ë³‘ë ¬ ì²˜ë¦¬ ì¶”ê°€ |

---

## I-36: Quantitative Position/Disparity í•­ìƒ None

> **ë°œê²¬**: 2025-12-31 | **í•´ê²°**: 2025-12-31 âœ… | **íê¸°**: 2026-01-02 ğŸ”„ DEPRECATED

---

âš ï¸ **DEPRECATED** (2026-01-02)

ì´ ì´ìŠˆëŠ” **ì„ì‹œ í•´ê²°ì±…**ì´ì—ˆìœ¼ë©°, **I-41**ì—ì„œ ì›ë³¸ ì„¤ê³„ëŒ€ë¡œ `priceQuantitative` ë©”íŠ¸ë¦­ì„ êµ¬í˜„í•˜ì—¬ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.

**íê¸° ì´ìœ **:
- ì›ë³¸ ì„¤ê³„(`prompt/1_guideline(function).ini`:892-897)ëŠ” `priceQuantitative` **ë©”íŠ¸ë¦­** ì‚¬ìš©ì„ ìš”êµ¬
- ì´ í•´ê²°ì±…ì€ `calcFairValue` **íŒŒë¼ë¯¸í„°**ë¡œ ìš°íšŒí•˜ì—¬ ì„¤ê³„ ë¶ˆì¼ì¹˜ ë°œìƒ
- `config_lv2_metric` í…Œì´ë¸”ì— ë©”íŠ¸ë¦­ì„ ì •ì˜í•˜ì§€ ì•Šì•„ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ë¶ˆì¼ì¹˜

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ**:
- `calcFairValue` íŒŒë¼ë¯¸í„° â†’ I-41 ë°°í¬ í›„ ì œê±° ì˜ˆì •
- ì•„ë˜ êµ¬í˜„ëœ í•¨ìˆ˜ë“¤(`get_peer_tickers`, `calculate_sector_average_metrics` ë“±)ì€ **I-41ì—ì„œ ì¬ì‚¬ìš©ë¨**

**ì°¸ì¡°**:
- â†’ [I-41: priceQuantitative ë©”íŠ¸ë¦­ êµ¬í˜„]
- â†’ [ì„¤ê³„ ë¬¸ì„œ: backend/DESIGN_priceQuantitative_metric.md]
- â†’ [ì´ìŠˆ ë¶„ì„: history/ISSUE_priceQuantitative_MISSING.md]

---

### I-36-A: êµ¬í˜„ëœ í•¨ìˆ˜ë“¤ (I-41ì—ì„œ ì¬ì‚¬ìš©)

**1. get_peer_tickers() - ë™ì¢… ì—…ì¢… í‹°ì»¤ ì¡°íšŒ**

```python
# valuation_service.py
async def get_peer_tickers(ticker: str) -> List[str]:
    """
    fmp-stock-peers APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì¢… ì—…ì¢… í‹°ì»¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ì£¼ì˜: fmp-stock-peers APIëŠ” í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ ë°ì´í„°ë§Œ ë°˜í™˜í•˜ë¯€ë¡œ,
    symbol(ticker) ê°’ë§Œ ì‚¬ìš©í•˜ê³  ë‹¤ë¥¸ ê°’(price, mktCap ë“±)ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (I-36)
    """
    async with FMPAPIClient() as fmp_client:
        response = await fmp_client.call_api('fmp-stock-peers', {'ticker': ticker})
        # symbol(ticker) ê°’ë§Œ ì¶”ì¶œ
        peer_tickers = [peer['symbol'] for peer in response[0]['peerTickers']]
        return peer_tickers
```

**2. calculate_sector_average_metrics() - ì—…ì¢… í‰ê·  ê³„ì‚°**

```python
async def calculate_sector_average_metrics(
    pool,
    peer_tickers: List[str],
    event_date,
    metrics_by_domain: Dict[str, List[Dict[str, Any]]],
    target_metrics: List[str] = ['PER', 'PBR']
) -> Dict[str, float]:
    """
    ë™ì¢… ì—…ì¢… í‹°ì»¤ë“¤ì˜ í‰ê·  PER, PBR ë“±ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ìµœëŒ€ 10ê°œ peerë§Œ ì‚¬ìš© (ì„±ëŠ¥)
    - IQR ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ ì œê±°
    - event_date ê¸°ì¤€ ì‹œê°„ì  ìœ íš¨ì„± ì ìš©
    """
    # ê° peer í‹°ì»¤ì˜ ì¬ë¬´ì œí‘œ ì¡°íšŒ í›„ PER/PBR ê³„ì‚°
    # IQR ì´ìƒì¹˜ ì œê±° í›„ í‰ê·  ë°˜í™˜
    return {'PER': 25.5, 'PBR': 3.2}
```

**3. calculate_fair_value_from_sector() - ì ì •ê°€ ê³„ì‚°**

```python
def calculate_fair_value_from_sector(
    value_quantitative: Dict[str, Any],
    sector_averages: Dict[str, float],
    current_price: float
) -> Optional[float]:
    """
    ì ì •ê°€ = (ì—…ì¢… í‰ê·  PER) Ã— EPS
    EPS = í˜„ì¬ ì£¼ê°€ / í˜„ì¬ PER
    """
    current_per = value_quantitative['valuation']['PER']
    sector_avg_per = sector_averages['PER']
    
    eps = current_price / current_per
    fair_value = sector_avg_per * eps
    return fair_value
```

**4. calculate_fair_value_for_ticker() - í†µí•© í•¨ìˆ˜**

```python
async def calculate_fair_value_for_ticker(
    pool, ticker, event_date, value_quantitative, current_price, metrics_by_domain
) -> Dict[str, Any]:
    """
    íŠ¹ì • í‹°ì»¤ì˜ ì—…ì¢… í‰ê·  ê¸°ë°˜ ì ì •ê°€ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Returns:
        {
            'fair_value': 80.0,
            'position': 'short',
            'disparity': -0.20,
            'sector_averages': {'PER': 20.0, 'PBR': 2.5},
            'peer_count': 8
        }
    """
```

### I-36-B: íŒŒë¼ë¯¸í„° ì¶”ê°€

**BackfillEventsTableQueryParams (request_models.py)**

```python
calc_fair_value: bool = Field(
    default=False,
    alias="calcFairValue",
    description="If true, calculate sector-average-based fair value for position_quantitative"
)
```

### I-36-C: í˜¸ì¶œ íë¦„

```python
# process_ticker_batch() ë‚´ë¶€
if calc_fair_value:
    fair_value_result = await calculate_fair_value_for_ticker(...)
    position_quant = fair_value_result.get('position')
    disparity_quant = fair_value_result.get('disparity')
    
    # _fairValue ì •ë³´ë¥¼ value_quantitativeì— ì¶”ê°€
    quant_result['value']['valuation']['_fairValue'] = {
        'value': fair_value_result.get('fair_value'),
        'sectorAverages': fair_value_result.get('sector_averages'),
        'peerCount': fair_value_result.get('peer_count')
    }
else:
    # Default: NULL (ê¸°ì¡´ ë™ì‘)
    position_quant, disparity_quant = calculate_position_disparity(...)
```

### I-36-D: ì‚¬ìš©ë²•

```bash
# ì—…ì¢… í‰ê·  ê¸°ë°˜ ì ì •ê°€ ê³„ì‚° í™œì„±í™”
POST /backfillEventsTable?calcFairValue=true&tickers=AAPL

# ê¸°ë³¸ (calcFairValue=false): position_quantitative, disparity_quantitativeëŠ” NULL
POST /backfillEventsTable?tickers=AAPL
```

### I-36-E: ì¶œë ¥ ì˜ˆì‹œ

```json
{
  "value_quantitative": {
    "valuation": {
      "PER": 25.3,
      "PBR": 3.2,
      "_fairValue": {
        "value": 145.50,
        "sectorAverages": {"PER": 22.5, "PBR": 2.8},
        "peerCount": 8
      }
    }
  },
  "position_quantitative": "short",
  "disparity_quantitative": -0.12
}
```

### I-36-F: ì˜í–¥ ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|-----------|
| `backend/src/services/valuation_service.py` | 4ê°œ í•¨ìˆ˜ ì¶”ê°€, process_ticker_batch ìˆ˜ì • |
| `backend/src/models/request_models.py` | calc_fair_value íŒŒë¼ë¯¸í„° ì¶”ê°€ |
| `backend/src/routers/events.py` | calc_fair_value ì „ë‹¬ |

---

## I-37: targetMedian ëª…ì¹­/ê°’ ë¶ˆì¼ì¹˜ (í‰ê·  vs ì¤‘ì•™ê°’)

> **ë°œê²¬**: 2025-12-31 | **í•´ê²°**: 2025-12-31 âœ…

### I-37-A: ìˆ˜ì •ëœ SQL ì¿¼ë¦¬

**calculate_target_summary() ìœ„ì¹˜**: `backend/src/database/queries/consensus.py:239-304`

```sql
-- ìˆ˜ì •ëœ ì¿¼ë¦¬: PERCENTILE_CONTë¡œ Median ì¶”ê°€, Min/Max ì¶”ê°€
WITH base_data AS (
    SELECT 
        price_target,
        analyst_company,
        event_date,
        $2::timestamptz AS ref_date
    FROM evt_consensus
    WHERE ticker = $1
      AND event_date <= $2::timestamptz
      AND price_target IS NOT NULL
)
SELECT
    -- Last Month (30 days) - Count, Median, Avg
    COUNT(*) FILTER (WHERE event_date > ref_date - INTERVAL '30 days') AS last_month_count,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price_target) 
        FILTER (WHERE event_date > ref_date - INTERVAL '30 days') AS last_month_median,
    AVG(price_target) FILTER (WHERE event_date > ref_date - INTERVAL '30 days') AS last_month_avg,
    
    -- Last Quarter (90 days) - Count, Median, Avg
    COUNT(*) FILTER (WHERE event_date > ref_date - INTERVAL '90 days') AS last_quarter_count,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price_target) 
        FILTER (WHERE event_date > ref_date - INTERVAL '90 days') AS last_quarter_median,
    AVG(price_target) FILTER (WHERE event_date > ref_date - INTERVAL '90 days') AS last_quarter_avg,
    
    -- Last Year (365 days) - Count, Median, Avg
    COUNT(*) FILTER (WHERE event_date > ref_date - INTERVAL '365 days') AS last_year_count,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price_target) 
        FILTER (WHERE event_date > ref_date - INTERVAL '365 days') AS last_year_median,
    AVG(price_target) FILTER (WHERE event_date > ref_date - INTERVAL '365 days') AS last_year_avg,
    
    -- All Time (Count, Median, Avg, Min, Max)
    COUNT(*) AS all_time_count,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY price_target) AS all_time_median,
    AVG(price_target) AS all_time_avg,
    MIN(price_target) AS all_time_min,
    MAX(price_target) AS all_time_max,
    
    -- Publishers
    ARRAY_AGG(DISTINCT analyst_company) FILTER (WHERE analyst_company IS NOT NULL) AS publishers
FROM base_data
```

### I-37-B: ìˆ˜ì •ëœ Python ë°˜í™˜ êµ¬ì¡°

```python
# consensus.py - ìˆ˜ì •ë¨
return {
    # Last Month
    'lastMonthCount': row['last_month_count'] or 0,
    'lastMonthMedianPriceTarget': round(float(row['last_month_median']), 2) if row['last_month_median'] else None,
    'lastMonthAvgPriceTarget': round(float(row['last_month_avg']), 2) if row['last_month_avg'] else None,
    # Last Quarter
    'lastQuarterCount': row['last_quarter_count'] or 0,
    'lastQuarterMedianPriceTarget': round(float(row['last_quarter_median']), 2) if row['last_quarter_median'] else None,
    'lastQuarterAvgPriceTarget': round(float(row['last_quarter_avg']), 2) if row['last_quarter_avg'] else None,
    # Last Year
    'lastYearCount': row['last_year_count'] or 0,
    'lastYearMedianPriceTarget': round(float(row['last_year_median']), 2) if row['last_year_median'] else None,
    'lastYearAvgPriceTarget': round(float(row['last_year_avg']), 2) if row['last_year_avg'] else None,
    # All Time (with Min/Max)
    'allTimeCount': row['all_time_count'] or 0,
    'allTimeMedianPriceTarget': round(float(row['all_time_median']), 2) if row['all_time_median'] else None,
    'allTimeAvgPriceTarget': round(float(row['all_time_avg']), 2) if row['all_time_avg'] else None,
    'allTimeMinPriceTarget': round(float(row['all_time_min']), 2) if row['all_time_min'] else None,
    'allTimeMaxPriceTarget': round(float(row['all_time_max']), 2) if row['all_time_max'] else None,
    # Publishers
    'publishers': row['publishers'] or []
}
```

### I-37-C: ìˆ˜ì •ëœ ë³€ìˆ˜ í• ë‹¹

```python
# valuation_service.py - ìˆ˜ì •ë¨
# ì‹¤ì œ Median ê°’ ì‚¬ìš© (I-37)
target_median = target_summary.get('allTimeMedianPriceTarget')  # â† ì‹¤ì œ ì¤‘ì•™ê°’
target_average = target_summary.get('allTimeAvgPriceTarget')    # â† í‰ê· ê°’ë„ ë³„ë„ ì €ì¥
```

### I-37-D: ë°ì´í„° ì¬ê³„ì‚°

```bash
# Phase 3 ì¬ì‹¤í–‰í•˜ì—¬ target_summary ì—…ë°ì´íŠ¸
GET /sourceData?mode=consensus&overwrite=true
```

### I-37-E: ì˜í–¥ ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|-----------|
| `backend/src/database/queries/consensus.py` | PERCENTILE_CONT ì¶”ê°€, Min/Max ì¶”ê°€ |
| `backend/src/services/valuation_service.py` | allTimeMedianPriceTarget ì‚¬ìš© |

---

## I-38: calcFairValue ê¸°ë³¸ê°’ Falseë¡œ ì¸í•œ NULL âœ…

**ë°œê²¬**: 2026-01-01
**í•´ê²°**: 2026-01-01
**íê¸°**: 2026-01-02 ğŸ”„ DEPRECATED
**ë¶„ë¥˜**: ì—”ë“œí¬ì¸íŠ¸ íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ì´ìŠˆ

---

âš ï¸ **DEPRECATED** (2026-01-02)

`calcFairValue` íŒŒë¼ë¯¸í„° ìì²´ê°€ ì„ì‹œ í•´ê²°ì±…ì´ì—ˆìœ¼ë©°, **I-41**ì—ì„œ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œì— í†µí•©ë˜ì–´ ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**íê¸° ì´ìœ **:
- íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì ‘ê·¼ì€ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ë¶ˆì¼ì¹˜
- I-41ì—ì„œ `priceQuantitative` ë©”íŠ¸ë¦­ì„ `config_lv2_metric`ì— ì •ì˜í•˜ë©´ ìë™ìœ¼ë¡œ ê³„ì‚°ë¨
- ëª…ì‹œì  íŒŒë¼ë¯¸í„° ì „ë‹¬ ë¶ˆí•„ìš”

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ**:
- I-41 ë°°í¬ í›„ `calcFairValue` íŒŒë¼ë¯¸í„° ì œê±° ì˜ˆì •
- ë©”íŠ¸ë¦­ì´ `metrics_by_domain`ì— í¬í•¨ë˜ë©´ ìë™ ê³„ì‚°

**ì°¸ì¡°**:
- â†’ [I-41: priceQuantitative ë©”íŠ¸ë¦­ êµ¬í˜„]

---

### I-38-A: ë¬¸ì œ í˜„ìƒ (ì°¸ê³ ìš©)

txn_events í…Œì´ë¸” ê²€ì¦ ê²°ê³¼:
```
position_quantitative:  136,954ê°œ (100.00% NULL) âŒ
disparity_quantitative: 136,954ê°œ (100.00% NULL) âŒ
value_qualitative:      77,375ê°œ (56.50% NULL)  âš ï¸ (ì˜ë„ëœ ë™ì‘ - earning ì´ë²¤íŠ¸ ë¹„ìœ¨)
position_qualitative:   77,380ê°œ (56.50% NULL)  âš ï¸
disparity_qualitative:  77,380ê°œ (56.50% NULL)  âš ï¸
```

**ê·¼ë³¸ ì›ì¸**:
- I-36ì—ì„œ `calcFairValue` íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ì—…ì¢… í‰ê·  ê¸°ë°˜ ì ì •ê°€ ê³„ì‚°ì„ êµ¬í˜„í–ˆìœ¼ë‚˜, ê¸°ë³¸ê°’ì´ `False`ë¡œ ì„¤ì •ë¨
- ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ `?calcFairValue=true`ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ position_quantitative/disparity_quantitativeê°€ ê³„ì‚°ë˜ì§€ ì•ŠìŒ
- Quantitative metricsëŠ” price targetì´ ì—†ìœ¼ë¯€ë¡œ, fair value ê³„ì‚° ì—†ì´ëŠ” position/disparityë¥¼ ì‚°ì¶œí•  ìˆ˜ ì—†ìŒ

**ì˜í–¥ë°›ì€ íŒŒì¼**:
- `backend/src/models/request_models.py:248` - `calc_fair_value: bool = Field(default=False)`
- `backend/src/services/valuation_service.py:441` - `calc_fair_value: bool = False`

### I-38-B: í•´ê²° ë°©ë²•

**ì˜µì…˜ A**: calcFairValue ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½ âœ… (ì„ íƒë¨)
- ì¥ì : íŒŒë¼ë¯¸í„° ì—†ì´ë„ ìë™ìœ¼ë¡œ position/disparity ê³„ì‚°
- ë‹¨ì : fmp-stock-peers API ì¶”ê°€ í˜¸ì¶œ (ì„±ëŠ¥ ì˜í–¥ ë¯¸ë¯¸, í‹°ì»¤ë‹¹ 1íšŒ)

**ì˜µì…˜ B**: ê¸°ë³¸ê°’ ìœ ì§€í•˜ê³  ë¬¸ì„œí™” ê°•í™”
- ì¥ì : API í˜¸ì¶œ ìµœì†Œí™”
- ë‹¨ì : ì‚¬ìš©ìê°€ ë§¤ë²ˆ íŒŒë¼ë¯¸í„° ì§€ì • í•„ìš”, UX ì €í•˜

### I-38-C: êµ¬í˜„ ë‚´ìš©

#### 1. request_models.py ìˆ˜ì •

```python
# backend/src/models/request_models.py:247-251
calc_fair_value: bool = Field(
    default=True,  # â† Falseì—ì„œ Trueë¡œ ë³€ê²½
    alias="calcFairValue",
    description="If true, calculate sector-average-based fair value for position_quantitative and disparity_quantitative. This requires additional API calls to fmp-stock-peers and peer financials. (I-36, I-38: default changed to True)"
)
```

#### 2. valuation_service.py ìˆ˜ì •

```python
# backend/src/services/valuation_service.py:435-442
async def calculate_valuations(
    overwrite: bool = False,
    from_date: Optional[date] = None,
    to_date: Optional[date] = None,
    tickers: Optional[List[str]] = None,
    cancel_event: Optional[asyncio.Event] = None,
    calc_fair_value: bool = True  # â† Falseì—ì„œ Trueë¡œ ë³€ê²½
) -> Dict[str, Any]:
```

### I-38-D: ê²€ì¦ ë°©ë²•

```bash
# ê¸°ë³¸ í˜¸ì¶œ (calcFairValue=trueê°€ ìë™ ì ìš©)
POST /backfillEventsTable

# ëª…ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥ (API í˜¸ì¶œ ì ˆê°)
POST /backfillEventsTable?calcFairValue=false

# ë°ì´í„° ê²€ì¦
python backend/check_valuation_nulls.py
```

**ì˜ˆìƒ ê²°ê³¼**:
- position_quantitative: NULL â†’ sector-based fair valueë¡œ ê³„ì‚°ëœ ê°’
- disparity_quantitative: NULL â†’ (fair_value / current_price) - 1

### I-38-E: ì˜í–¥ ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© | ë¼ì¸ |
|------|-----------|------|
| `backend/src/models/request_models.py` | calc_fair_value ê¸°ë³¸ê°’ Trueë¡œ ë³€ê²½ | 248 |
| `backend/src/services/valuation_service.py` | calc_fair_value ê¸°ë³¸ê°’ Trueë¡œ ë³€ê²½ | 441 |

### I-38-F: ê´€ë ¨ ì´ìŠˆ

- **I-36**: Quantitative Position/Disparity ê³„ì‚° êµ¬í˜„ (calcFairValue íŒŒë¼ë¯¸í„° ì¶”ê°€)
- **I-37**: targetMedian ì‹¤ì œ ì¤‘ì•™ê°’ ê³„ì‚° (PERCENTILE_CONT)

---

## I-39: target_summary JSONB ë¬¸ìì—´ íŒŒì‹± ì˜¤ë¥˜ âœ…

**ë°œê²¬**: 2026-01-02
**í•´ê²°**: 2026-01-02
**ë¶„ë¥˜**: JSONB ë°ì´í„° íƒ€ì… ì²˜ë¦¬ ì´ìŠˆ

### I-39-A: ë¬¸ì œ í˜„ìƒ

POST /backfillEventsTable ì‹¤í–‰ ì‹œ ëª¨ë“  consensus ì´ë²¤íŠ¸ì˜ qualitative ê³„ì‚° ì‹¤íŒ¨:

```
Error: 'str' object has no attribute 'get'
qualitativeSuccess: 0/10 (0%)
qualitativeFail: 10/10 (100%)
```

### I-39-B: ê·¼ë³¸ ì›ì¸

**backend/src/database/queries/metrics.py:178-219 (select_consensus_data)**

asyncpgê°€ PostgreSQLì˜ jsonb íƒ€ì…ì„ Python ë¬¸ìì—´ë¡œ ë°˜í™˜í•˜ëŠ”ë°, ì½”ë“œëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ì˜ˆìƒí•˜ê³  `.get()` ë©”ì„œë“œ í˜¸ì¶œ:

```python
# DB ì¡°íšŒ ê²°ê³¼
target_summary = row['target_summary']  # â† str íƒ€ì…
target_median = target_summary.get('allTimeMedianPriceTarget')  # âŒ Error
```

### I-39-C: í•´ê²° ë°©ë²•

select_consensus_data í•¨ìˆ˜ì— JSON íŒŒì‹± ì¶”ê°€:

```python
# backend/src/database/queries/metrics.py:227-234
import json

result = dict(row)

# I-39: Parse target_summary from JSON string to dict
if result.get('target_summary') and isinstance(result['target_summary'], str):
    try:
        result['target_summary'] = json.loads(result['target_summary'])
    except (json.JSONDecodeError, TypeError):
        pass

return result
```

### I-39-D: ê²€ì¦ ê²°ê³¼

**ìˆ˜ì • í›„**:
- qualitativeSuccess: **10/10 (100%)** âœ…
- qualitativeFail: **0 (0%)** âœ…
- Consensus ì´ë²¤íŠ¸ ì •ìƒ ì²˜ë¦¬

---

## I-40: Peer tickers ë¯¸ì¡´ì¬ ì‹œ position_quantitative NULL

**ë°œê²¬**: 2026-01-02
**í•´ê²°**: 2026-01-02 (ì„¤ê³„ìƒ ì˜ˆìƒ ë™ì‘)
**íê¸°**: 2026-01-02 ğŸ”„ DEPRECATED
**ë¶„ë¥˜**: Fair value ê³„ì‚° ì œí•œì‚¬í•­

---

âš ï¸ **DEPRECATED** (2026-01-02)

ì´ ì´ìŠˆëŠ” ë³„ë„ ì´ìŠˆê°€ ì•„ë‹Œ **I-41 priceQuantitative ë©”íŠ¸ë¦­ì˜ ì•Œë ¤ì§„ ì œí•œì‚¬í•­**ìœ¼ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.

**íê¸° ì´ìœ **:
- Peer tickers ë¯¸ì¡´ì¬ ì‹œ NULLì€ `priceQuantitative` ë©”íŠ¸ë¦­ì˜ **ì„¤ê³„ìƒ ì œí•œì‚¬í•­**
- ë³„ë„ ì´ìŠˆë¡œ ê´€ë¦¬í•  í•„ìš” ì—†ì´, ë©”íŠ¸ë¦­ ë¬¸ì„œì— ì œí•œì‚¬í•­ìœ¼ë¡œ ëª…ì‹œ

**í†µí•© ìœ„ì¹˜**:
- I-41 "ì•Œë ¤ì§„ ì œí•œì‚¬í•­" ì„¹ì…˜ì— í¬í•¨ë¨
- `backend/DESIGN_priceQuantitative_metric.md` ë¬¸ì„œì— ìƒì„¸íˆ ê¸°ë¡

**ì°¸ì¡°**:
- â†’ [I-41: priceQuantitative ë©”íŠ¸ë¦­ êµ¬í˜„]
- â†’ [ì„¤ê³„ ë¬¸ì„œ: backend/DESIGN_priceQuantitative_metric.md]

---

### I-40-A: ë¬¸ì œ í˜„ìƒ (ì°¸ê³ ìš©)

calcFairValue=true (ê¸°ë³¸ê°’)ì¸ë°ë„ position_quantitativeì™€ disparity_quantitativeê°€ null:

```json
{
  "position": {"qualitative": "long"},
  "disparity": {"qualitative": 0.58}
  // â† quantitativeëŠ” null
}
```

### I-40-B: ê·¼ë³¸ ì›ì¸

ì†Œí˜•ì£¼/íŠ¹ìˆ˜ ì„¹í„°ëŠ” FMP APIì—ì„œ peer tickersë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ:

```python
# backend/src/services/valuation_service.py:1873-1913
async def get_peer_tickers(ticker: str):
    response = await fmp_client.call_api('fmp-stock-peers', {'ticker': ticker})
    if not response or len(response) == 0:
        logger.warning(f"[I-36] No peer tickers found for {ticker}")
        return []  # â† ë¹ˆ ë¦¬ìŠ¤íŠ¸
```

**ê²°ê³¼**: peerê°€ ì—†ìœ¼ë©´ ì—…ì¢… í‰ê·  PER/PBR ê³„ì‚° ë¶ˆê°€ â†’ fair value ê³„ì‚° ë¶ˆê°€ â†’ position/disparity null

### I-40-C: ì„¤ê³„ ê²°ì •

**ì„ íƒ**: null ìœ ì§€ (ì •ìƒ ë™ì‘)

**ì´ìœ **:
- Peer tickers ì—†ì´ëŠ” fair value ê³„ì‚°ì´ ì˜ë¯¸ ì—†ìŒ
- ë¡œê·¸ì— ê²½ê³  ë©”ì‹œì§€ ê¸°ë¡ë¨
- ëŒ€ì²´ valuation ë°©ë²•ì€ í–¥í›„ ë³„ë„ ì´ìŠˆë¡œ ì²˜ë¦¬

**ì˜í–¥ë°›ëŠ” í‹°ì»¤**:
- ì†Œí˜•ì£¼ (market cap < $1B)
- íŠ¹ìˆ˜ ì„¹í„° (Quantum Computing ë“±)
- ìµœê·¼ ìƒì¥ ê¸°ì—…

---

## I-41: priceQuantitative ë©”íŠ¸ë¦­ ë¯¸êµ¬í˜„ (ì„¤ê³„ ë¶ˆì¼ì¹˜)

**ë°œê²¬**: 2026-01-02
**í•´ê²°**: 2026-01-02
**ë¶„ë¥˜**: ì„¤ê³„ ë¶ˆì¼ì¹˜ í•´ê²°

### I-41-A: ë¬¸ì œ ë°œê²¬

**ë°œë‹¨**: I-40 ê²€í†  ì¤‘ position_quantitativeê°€ nullì¸ ê²ƒì´ ì„¤ê³„ëŒ€ë¡œì¸ì§€ í™•ì¸ ìš”ì²­

**ì›ë³¸ ì„¤ê³„ ë¬¸ì„œ í™•ì¸** (`prompt/1_guideline(function).ini`:892-897):

```ini
position_quantitative: [table.metric] í…Œì´ë¸”ì˜ priceQuantitativeì¸ ê°’ì´
                      [table.metric] í…Œì´ë¸”ì˜ price ê°’ë³´ë‹¤ ì‘ë‹¤ë©´ short, í¬ë‹¤ë©´ long
    - ì¶œë ¥ ì˜ˆì‹œ: "long" | "short" | "undefined"

disparity_quantitative: {([table.metric] í…Œì´ë¸”ì˜ priceQuantitativeì¸ ê°’) /
                        ([table.metric] í…Œì´ë¸”ì˜ price ê°’)} - 1 ê°’ ê¸°ë¡
    - ì¶œë ¥ ì˜ˆì‹œ: -0.2
```

**ë°œê²¬**:
- ì›ë³¸ ì„¤ê³„ëŠ” `priceQuantitative` **ë©”íŠ¸ë¦­** ì‚¬ìš©ì„ ëª…ì‹œ
- ì‹¤ì œ êµ¬í˜„ì—ëŠ” `config_lv2_metric` í…Œì´ë¸”ì— í•´ë‹¹ ë©”íŠ¸ë¦­ ì—†ìŒ
- I-36ì—ì„œ `calcFairValue` **íŒŒë¼ë¯¸í„°**ë¡œ ìš°íšŒ êµ¬í˜„

**DB ê²€ì¦**:
```sql
SELECT id FROM config_lv2_metric WHERE id = 'priceQuantitative';
-- ê²°ê³¼: NOT FOUND
```

### I-41-B: ì„¤ê³„ vs êµ¬í˜„ ë¹„êµ

| í•­ëª© | ì›ë³¸ ì„¤ê³„ | ì‹¤ì œ êµ¬í˜„ (I-36) |
|------|----------|-----------------|
| **ë©”íŠ¸ë¦­ ì •ì˜** | priceQuantitative ë©”íŠ¸ë¦­ | NOT FOUND |
| **ê³„ì‚° ë°©ë²•** | ë©”íŠ¸ë¦­ ê¸°ë°˜ | íŒŒë¼ë¯¸í„° ê¸°ë°˜ |
| **ì ìš© ë²”ìœ„** | ëª¨ë“  ticker | Peer ìˆëŠ” tickerë§Œ |
| **ì•„í‚¤í…ì²˜** | ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ | íŒŒë¼ë¯¸í„° ì „ë‹¬ |

### I-41-C: LLM ì œê³µ ì„ íƒì§€

| ì˜µì…˜ | ì„¤ëª… | ë³µì¡ë„ |
|------|------|--------|
| **A** | **priceQuantitative ë©”íŠ¸ë¦­ êµ¬í˜„ (ì›ë³¸ ì„¤ê³„ ì¤€ìˆ˜)** | **ë†’ìŒ** |
| B | ì„¤ê³„ ë¬¸ì„œ ì—…ë°ì´íŠ¸ (í˜„í–‰ ìœ ì§€) | ë‚®ìŒ |
| C | í•˜ì´ë¸Œë¦¬ë“œ (ë©”íŠ¸ë¦­ + fallback) | ì¤‘ê°„ |

**ì‚¬ìš©ì ì„ íƒ**: **ì˜µì…˜ A** - ì›ë³¸ ì„¤ê³„ëŒ€ë¡œ ë©”íŠ¸ë¦­ êµ¬í˜„

### I-41-D: êµ¬í˜„ ë‚´ìš©

**1. ë©”íŠ¸ë¦­ ì •ì˜ SQL** (`backend/scripts/add_priceQuantitative_metric.sql`)

```sql
INSERT INTO config_lv2_metric (
    id,
    description,
    source,
    domain,
    aggregation_params
) VALUES (
    'priceQuantitative',
    'Fair value price based on sector-average valuation multiples. Calculated as: sector_avg_PER Ã— EPS (or sector_avg_PBR Ã— BPS if PER unavailable). Uses fmp-stock-peers API to determine peer group. Returns NULL if no peer tickers available.',
    'custom',
    'quantitative-valuation',
    '{
        "calculation_method": "sector_average_fair_value",
        "peer_api": "fmp-stock-peers",
        "valuation_metrics": ["PER", "PBR"],
        "max_peers": 10,
        "outlier_removal": "iqr_1.5"
    }'::jsonb
);
```

**2. ê³„ì‚° ë¡œì§** (I-36ì—ì„œ ê°œë°œí•œ í•¨ìˆ˜ ì¬ì‚¬ìš©)

**Step 1: ë™ì¢… ì—…ì¢… í‹°ì»¤ ì¡°íšŒ**
```python
# backend/src/services/valuation_service.py:get_peer_tickers()
peer_tickers = await fmp_client.call_api('fmp-stock-peers', {'ticker': ticker})
# ê²°ê³¼: ['MSFT', 'GOOGL', 'META', ...] (ìµœëŒ€ 10ê°œ)
```

**Step 2: ì—…ì¢… í‰ê·  PER/PBR ê³„ì‚°**
```python
# backend/src/services/valuation_service.py:calculate_sector_average_metrics()
# ê° peerì˜ PER/PBR ê³„ì‚° â†’ IQR ì´ìƒì¹˜ ì œê±° â†’ í‰ê· 
sector_averages = {'PER': 25.5, 'PBR': 3.2}
```

**Step 3: ì ì •ê°€ ê³„ì‚°**
```python
# backend/src/services/valuation_service.py:calculate_fair_value_from_sector()
if current_per and sector_avg_per:
    eps = current_price / current_per
    fair_value = sector_avg_per * eps  # priceQuantitative
else:
    bps = current_price / current_pbr
    fair_value = sector_avg_pbr * bps  # fallback
```

**Step 4: position/disparity ê³„ì‚°**
```python
# ì›ë³¸ ì„¤ê³„ëŒ€ë¡œ ê³„ì‚°
if fair_value and current_price:
    position_quantitative = 'long' if fair_value > current_price else 'short'
    disparity_quantitative = (fair_value / current_price) - 1
```

**3. ê²°ê³¼ êµ¬ì¡°**

```json
{
  "value_quantitative": {
    "valuation": {
      "PER": 28.5,
      "PBR": 7.2,
      "priceQuantitative": 185.0  // <- ìƒˆë¡œ ì¶”ê°€ëœ ë©”íŠ¸ë¦­
    }
  },
  "position_quantitative": "short",  // priceQuantitative vs price
  "disparity_quantitative": -0.075   // (185/200) - 1
}
```

### I-41-E: íê¸°ëœ ì´ìŠˆ

**I-36: calcFairValue íŒŒë¼ë¯¸í„° ë°©ì‹**
- ìƒíƒœ: ğŸ”„ DEPRECATED
- ì´ìœ : ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ì™€ ë¶ˆì¼ì¹˜
- ë§ˆì´ê·¸ë ˆì´ì…˜: I-41 ë°°í¬ í›„ calcFairValue íŒŒë¼ë¯¸í„° ì œê±° ì˜ˆì •
- ì¬ì‚¬ìš©: ê³„ì‚° ë¡œì§ í•¨ìˆ˜ë“¤ì€ I-41ì—ì„œ ì¬ì‚¬ìš©

**I-38: calcFairValue ê¸°ë³¸ê°’**
- ìƒíƒœ: ğŸ”„ DEPRECATED
- ì´ìœ : íŒŒë¼ë¯¸í„° ìì²´ê°€ ë¶ˆí•„ìš”í•´ì§
- ë§ˆì´ê·¸ë ˆì´ì…˜: ë©”íŠ¸ë¦­ì´ metrics_by_domainì— í¬í•¨ë˜ë©´ ìë™ ê³„ì‚°

**I-40: Peer tickers ë¯¸ì¡´ì¬ ì‹œ NULL**
- ìƒíƒœ: ğŸ”„ DEPRECATED (ë³„ë„ ì´ìŠˆ ì•„ë‹˜)
- ì´ìœ : priceQuantitative ë©”íŠ¸ë¦­ì˜ ì•Œë ¤ì§„ ì œí•œì‚¬í•­
- í†µí•©: I-41 ì„¤ê³„ ë¬¸ì„œì— ì œí•œì‚¬í•­ìœ¼ë¡œ ëª…ì‹œ

### I-41-F: ì•Œë ¤ì§„ ì œí•œì‚¬í•­

**1. Peer tickers ë¯¸ì¡´ì¬ ì‹œ NULL**

**ì˜í–¥ë°›ëŠ” í‹°ì»¤**:
- ì†Œí˜•ì£¼ (market cap < $1B)
- íŠ¹ìˆ˜ ì„¹í„° (Quantum Computing, ì‹ ê·œ ì‚°ì—…)
- ìµœê·¼ ìƒì¥ ê¸°ì—…

**ë™ì‘**:
```json
{
  "value_quantitative": {
    "valuation": {
      "PER": -19.09,
      "PBR": 18.02,
      "priceQuantitative": null  // <- peer ì—†ìŒ
    }
  },
  "position_quantitative": null,
  "disparity_quantitative": null
}
```

**ë¡œê·¸**: `[I-36] No peer tickers found for {ticker}, skipping fair value calculation`

**í–¥í›„ ê°œì„  ë°©ì•ˆ**:
- Manual peer ticker configuration
- Alternative valuation methods (P/S ratio, DCF)
- Machine learning-based fair value prediction

**2. ì‹œê°„ì  ë¶ˆì¼ì¹˜ (Temporal Inconsistency)**

**ì´ìŠˆ**: fmp-stock-peersëŠ” **í˜„ì¬** peer ëª©ë¡ë§Œ ì œê³µ

**ì˜í–¥**: ê³¼ê±° ì´ë²¤íŠ¸ backfill ì‹œ, ë‹¹ì‹œì˜ ì‹¤ì œ peer groupê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

**ì˜ˆì‹œ**:
- 2023ë…„ ì´ë²¤íŠ¸ ê³„ì‚° ì‹œ, 2026ë…„ í˜„ì¬ peer list ì‚¬ìš©
- 2023ë…„ê³¼ 2026ë…„ ì‚¬ì´ ì—…ì¢… ë³€ê²½ ê°€ëŠ¥ (ì˜ˆ: ì „ê¸°ì°¨ â†’ AI)

**ì´ê²ƒì€ FMP APIì˜ ì œí•œì‚¬í•­**ì´ë©°, ê·¼ë³¸ì  í•´ê²° ë¶ˆê°€

### I-41-G: ì˜í–¥ë°›ëŠ” íŒŒì¼

| íŒŒì¼ | ë³€ê²½ ë‚´ìš© | ìƒíƒœ |
|------|-----------|------|
| `backend/scripts/add_priceQuantitative_metric.sql` | ë©”íŠ¸ë¦­ ì •ì˜ INSERT | âœ… ì‘ì„± ì™„ë£Œ |
| `backend/DESIGN_priceQuantitative_metric.md` | ì„¤ê³„ ë¬¸ì„œ | âœ… ì‘ì„± ì™„ë£Œ |
| `history/ISSUE_priceQuantitative_MISSING.md` | ì´ìŠˆ ë¶„ì„ ë¬¸ì„œ | âœ… ì‘ì„± ì™„ë£Œ |
| `backend/src/services/metric_engine.py` | source='custom' ì§€ì› | â³ TODO |
| `backend/src/services/valuation_service.py` | ë©”íŠ¸ë¦­ ì—”ì§„ í†µí•© | â³ TODO |
| `backend/src/models/request_models.py` | calcFairValue ì œê±° | â³ TODO (I-41 ë°°í¬ í›„) |

### I-41-H: ë‹¤ìŒ ë‹¨ê³„

**ì¦‰ì‹œ**:
1. âœ… SQL ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰: `add_priceQuantitative_metric.sql`
2. â³ Metric engineì— `source='custom'` í•¸ë“¤ëŸ¬ ì¶”ê°€
3. â³ Valuation serviceì™€ metric engine í†µí•©
4. â³ í…ŒìŠ¤íŠ¸: POST /backfillEventsTable

**ë°°í¬ í›„**:
1. calcFairValue íŒŒë¼ë¯¸í„° ì œê±°
2. ê´€ë ¨ ë¬¸ì„œ ì—…ë°ì´íŠ¸
3. ì‚¬ìš©ì ê³µì§€

**í–¥í›„**:
1. Alternative valuation methods ì—°êµ¬
2. Manual peer configuration ì§€ì›
3. ML-based fair value prediction

---

*ìµœì¢… ì—…ë°ì´íŠ¸: 2026-01-02 KST (I-41 êµ¬í˜„ ì™„ë£Œ - priceQuantitative ë©”íŠ¸ë¦­ ì¶”ê°€, I-36/I-38/I-40 deprecated)*
*ì„¤ê³„ ë¬¸ì„œ: backend/DESIGN_priceQuantitative_metric.md*
*ì´ìŠˆ ë¶„ì„: history/ISSUE_priceQuantitative_MISSING.md*
*ì„¸ì…˜ ìš”ì•½: history/SESSION_2026-01-02_I39_I40_SUMMARY.md*
